import sys
import os
import argparse
import numpy as np
import matplotlib.pyplot as plt
import torch
import math
from tqdm import tqdm
from omegaconf import OmegaConf

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from src.models.flow_bert_multiview.models.flow_bert_multiview import FlowBertMultiview
from src.models.flow_bert_multiview.data.flow_bert_multiview_dataset import MultiviewFlowDataModule
from src.concept_drift_detect.detectors import BNDMDetector
from src.concept_drift_detect.run_experiment import MappingWrapper, resolve_path, find_valid_checkpoint


def calculate_mad(data):
    if len(data) == 0: return 0, 0
    median = np.median(data)
    abs_deviation = np.abs(data - median)
    mad = np.median(abs_deviation)
    return median, mad


def analyze_dynamic_threshold(model, dataloader, initial_threshold_log, device='cuda'):
    """
    æ¨¡æ‹ŸåŠ¨æ€ç›‘æµ‹è¿‡ç¨‹ï¼šæ£€æµ‹åˆ°æ¼‚ç§» -> è§¦å‘ Reset -> ç»§ç»­ç›‘æµ‹ã€‚
    """
    model.eval()
    model.to(device)

    # åˆå§‹åŒ–æ£€æµ‹å™¨
    config = {
        'seed': 2026,
        'threshold': math.exp(initial_threshold_log),  # è½¬æ¢ä¸ºæ¦‚ç‡é˜ˆå€¼
        'max_level': 6,
        'window_size': 1000,
        'alpha_scale': 0.1
    }
    detector = BNDMDetector(config)

    all_log_bfs = []
    drift_points = []

    print(f"æ­£åœ¨å…¨é‡æ•°æ®ä¸Šè¿è¡ŒåŠ¨æ€ç›‘æµ‹ (Log BF Threshold: {initial_threshold_log})...")

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Monitoring"):
            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
            outputs = model(batch)
            features = outputs['multiview_embeddings']

            for i in range(features.shape[0]):
                val = detector.preprocess(features[i].unsqueeze(0))

                # 1. è®°å½•å½“å‰ Log BF (åœ¨æ›´æ–°å‰è·å–çŠ¶æ€)
                if detector.is_initialized:
                    bf = detector._get_total_bf()
                    all_log_bfs.append(bf)
                else:
                    # åˆå§‹åŒ–é˜¶æ®µæ²¡æœ‰ BFï¼Œå¡« 0 æˆ– NaN
                    all_log_bfs.append(0.0)

                # 2. æ‰§è¡Œæ›´æ–°
                is_drift = detector.update(val)

                # 3. ğŸ”´ å…³é”®ä¿®å¤ï¼šæ£€æµ‹åˆ°æ¼‚ç§»åï¼Œå¿…é¡»æ˜¾å¼é‡ç½®ï¼
                if is_drift:
                    drift_points.append(len(all_log_bfs) - 1)
                    detector.reset()  # <--- åŠ ä¸Šè¿™ä¸€è¡Œï¼Œè®© BF å›å‡

    return np.array(all_log_bfs), drift_points


def plot_dynamic_analysis(log_bfs, drift_points, initial_th, save_path="dynamic_drift_analysis.png"):
    if len(log_bfs) == 0:
        print("æœªæ”¶é›†åˆ°æ•°æ®ã€‚")
        return

    # è¿‡æ»¤æ‰åˆå§‹åŒ–é˜¶æ®µçš„ 0 å€¼ï¼Œåªç»Ÿè®¡æœ‰æ•ˆ BF
    valid_bfs = log_bfs[log_bfs != 0]
    if len(valid_bfs) == 0: valid_bfs = log_bfs

    median, mad = calculate_mad(valid_bfs)

    plt.figure(figsize=(15, 8))

    # ç»˜åˆ¶ Log BF æ›²çº¿
    plt.plot(log_bfs, label='Log Bayes Factor', color='blue', linewidth=0.6, alpha=0.7)

    # ç»˜åˆ¶æ£€æµ‹åˆ°æ¼‚ç§»å¹¶â€œé‡ç½®â€çš„æ—¶åˆ» (çº¢çº¿)
    for i, pt in enumerate(drift_points):
        plt.axvline(x=pt, color='red', linestyle=':', linewidth=1.0, alpha=0.5,
                    label='Drift Reset' if i == 0 else "")

    # ç»˜åˆ¶ç»Ÿè®¡çº¿
    plt.axhline(median, color='green', linestyle='-', label=f'Median: {median:.2f}')
    plt.axhline(initial_th, color='black', linestyle='--', linewidth=2, label=f'Threshold: {initial_th}')

    plt.title(f'Log Bayes Factor Dynamics (Threshold={initial_th})\nRed lines indicate detector RESET')
    plt.xlabel('Sample Sequence')
    plt.ylabel('Log Bayes Factor')
    plt.legend(loc='lower left')
    plt.grid(True, alpha=0.2)
    plt.tight_layout()
    plt.savefig(save_path)
    print(f"\nâœ… åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
    print(f"ç»Ÿè®¡ç»“æœ: å…±è§¦å‘ {len(drift_points)} æ¬¡é‡ç½®ã€‚")
    print(f"æœ‰æ•ˆæ•°æ®ç»Ÿè®¡ - Median: {median:.4f}, MAD: {mad:.4f}")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--config_name", type=str, default="flow_bert_multiview_config")
    parser.add_argument("--dataset_name", type=str, default="cic_ids_2017")
    # ğŸ”´ å»ºè®®é»˜è®¤é˜ˆå€¼è®¾ä½ä¸€ç‚¹ï¼Œæ¯”å¦‚ -200ï¼Œä»¥è§‚å¯Ÿæ­£å¸¸éœ‡è¡
    parser.add_argument("--initial_log_th", type=float, default=-200.0, help="Log BF é˜ˆå€¼")
    args = parser.parse_args()

    # 1. é…ç½®åŠ è½½ä¸ä¿®æ­£
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.abspath(os.path.join(current_dir, "../../"))
    config_path = os.path.join(project_root, "src/models/flow_bert_multiview/config")

    cfg = OmegaConf.load(os.path.join(config_path, f"{args.config_name}.yaml"))
    dataset_cfg = OmegaConf.load(os.path.join(config_path, f"datasets/{args.dataset_name}.yaml"))

    # è§£å†³ InterpolationKeyError
    if 'dataset' not in cfg: cfg.dataset = OmegaConf.create()
    cfg.dataset.name = dataset_cfg.name
    cfg.dataset[dataset_cfg.name] = dataset_cfg

    if 'datasets' not in cfg: cfg.datasets = OmegaConf.create()
    cfg.datasets[dataset_cfg.name] = dataset_cfg
    cfg.datasets = OmegaConf.merge(cfg.datasets, dataset_cfg)
    cfg.data = OmegaConf.merge(cfg.data, dataset_cfg)

    # æ‰‹åŠ¨è§£æè·¯å¾„
    cfg.data.flow_data_path = resolve_path(dataset_cfg.flow_data_path, dataset_cfg.name)
    cfg.data.session_split.session_split_path = resolve_path(dataset_cfg.session_split_path, dataset_cfg.name)

    cfg.data.split_mode = "flow"
    if 'sampling' not in cfg.data: cfg.data.sampling = {}
    cfg.data.sampling.random = False

    # 2. æ•°æ®å‡†å¤‡
    print("æ­£åœ¨åˆå§‹åŒ– DataModule...")
    dm = MultiviewFlowDataModule(cfg)
    dm.setup(stage="fit")

    target_loader = dm.val_dataloader()
    if not target_loader or len(target_loader) == 0:
        target_loader = dm.test_dataloader()

    # 3. æ¨¡å‹åŠ è½½
    train_ds = dm.train_dataset
    dataset_wrapper = MappingWrapper(train_ds.categorical_val2idx_mappings,
                                     train_ds.categorical_columns_effective)

    ckpt_path = find_valid_checkpoint(project_root)
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {ckpt_path}")
    model = FlowBertMultiview.load_from_checkpoint(ckpt_path, cfg=cfg, dataset=dataset_wrapper)

    # 4. æ‰§è¡ŒåŠ¨æ€åˆ†æ
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    log_bfs, drift_points = analyze_dynamic_threshold(model, target_loader, args.initial_log_th, device)

    # 5. ç»˜å›¾
    plot_dynamic_analysis(log_bfs, drift_points, args.initial_log_th,
                          save_path=os.path.join(project_root, "dynamic_drift_analysis.png"))


if __name__ == "__main__":
    main()