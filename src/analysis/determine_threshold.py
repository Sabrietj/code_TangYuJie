import sys
import os
import argparse
import numpy as np
import matplotlib.pyplot as plt
import torch
import math
from tqdm import tqdm
from omegaconf import OmegaConf

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Pathï¼Œç¡®ä¿å¯ä»¥å¯¼å…¥ src æ¨¡å—
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from src.models.flow_bert_multiview.models.flow_bert_multiview import FlowBertMultiview
from src.models.flow_bert_multiview.data.flow_bert_multiview_dataset import MultiviewFlowDataModule
from src.concept_drift_detect.detectors import BNDMDetector
from src.concept_drift_detect.run_experiment import MappingWrapper, resolve_path, find_valid_checkpoint


def calculate_mad(data):
    """è®¡ç®—ç»å¯¹ä¸­ä½å·® (Median Absolute Deviation)"""
    if len(data) == 0:
        return 0, 0
    median = np.median(data)
    abs_deviation = np.abs(data - median)
    mad = np.median(abs_deviation)
    return median, mad


def analyze_threshold(model, dataloader, device='cuda'):
    """
    è¿è¡Œ BNDM æ£€æµ‹å™¨ï¼Œè®°å½• Log Bayes Factor çš„å˜åŒ–ï¼Œä¸è§¦å‘é‡ç½®ã€‚
    """
    model.eval()
    if torch.cuda.is_available():
        model.to(device)
    else:
        device = 'cpu'
        model.to(device)

    # åˆå§‹åŒ– BNDM æ£€æµ‹å™¨
    config = {
        'seed': 2026,
        'threshold': 1e-10,
        'max_level': 6,
        'window_size': 1000,
        'alpha_scale': 0.1
    }
    detector = BNDMDetector(config)

    # ğŸ”´ æ ¸å¿ƒæŠ€å·§ï¼šå°†é˜ˆå€¼è®¾ä¸ºè´Ÿæ— ç©·ï¼Œç¡®ä¿æ°¸è¿œä¸ä¼šè§¦å‘ detector.reset()
    detector.threshold = -float('inf')

    log_bfs = []
    processed_count = 0

    print("æ­£åœ¨åˆ†æ Log Bayes Factor åˆ†å¸ƒ...")

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Analyzing", unit="batch"):
            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}

            # 1. æ¨¡å‹æ¨ç†è·å–ç‰¹å¾
            try:
                outputs = model(batch)
                features = outputs['multiview_embeddings']  # (Batch, Dim)
            except Exception as e:
                print(f"âŒ æ¨¡å‹æ¨ç†å‡ºé”™ (å¯èƒ½æ˜¯è¾“å…¥ç‰¹å¾ç¼ºå¤±): {e}")
                continue

            # 2. é€æ ·æœ¬æ›´æ–°æ£€æµ‹å™¨
            batch_size = features.shape[0]
            for i in range(batch_size):
                feat = features[i].unsqueeze(0)

                # é¢„å¤„ç† (æŠ•å½± + å½’ä¸€åŒ–)
                val = detector.preprocess(feat)

                # æ›´æ–°æ£€æµ‹å™¨
                _ = detector.update(val)
                processed_count += 1

                # è®°å½•å½“å‰çš„ Log Bayes Factor
                # æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦ç­‰å¾… warm-up é˜¶æ®µè¿‡åæ•°æ®æ‰ç¨³å®š (å‚è€ƒçª—å£å¡«æ»¡å)
                if detector.is_initialized and processed_count > config['window_size']:
                    bf = detector._get_total_bf()
                    if not math.isnan(bf) and not math.isinf(bf):
                        log_bfs.append(bf)

    return np.array(log_bfs)


def plot_analysis(log_bfs, save_path="threshold_analysis.png"):
    """ç»˜åˆ¶ Log BF è¶‹åŠ¿å›¾å’Œç›´æ–¹å›¾ï¼Œå¹¶æ ‡è®°å»ºè®®é˜ˆå€¼"""
    if len(log_bfs) == 0:
        print("âŒ æ²¡æœ‰æ”¶é›†åˆ°è¶³å¤Ÿçš„ Log BF æ•°æ®ï¼ˆå¯èƒ½æ˜¯æ•°æ®é‡å¤ªå°‘ï¼Œæœªé€šè¿‡ Warm-up é˜¶æ®µï¼‰ã€‚")
        return

    # è®¡ç®—ç»Ÿè®¡é‡
    median, mad = calculate_mad(log_bfs)

    # æ ¹æ® MAD åŸåˆ™è®¡ç®—é˜ˆå€¼
    k_values = [3, 5, 10]
    thresholds = {k: median - k * mad for k in k_values}

    # ç»˜å›¾
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

    # å­å›¾ 1: æ—¶åºå˜åŒ–è¶‹åŠ¿
    ax1.plot(log_bfs, label='Log Bayes Factor', color='blue', alpha=0.6, linewidth=0.5)
    ax1.axhline(median, color='green', linestyle='--', label=f'Median ({median:.2f})')

    colors = ['orange', 'red', 'purple']
    for i, k in enumerate(k_values):
        th = thresholds[k]
        ax1.axhline(th, color=colors[i], linestyle='--', label=f'Threshold (k={k}): {th:.2f}')

    ax1.set_title('Log Bayes Factor Trend over Time (Stable Stream)')
    ax1.set_xlabel('Sample Index (after warm-up)')
    ax1.set_ylabel('Log Bayes Factor')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # å­å›¾ 2: åˆ†å¸ƒç›´æ–¹å›¾
    ax2.hist(log_bfs, bins=100, color='skyblue', edgecolor='black', alpha=0.7, density=True)
    ax2.axvline(median, color='green', linestyle='--', label='Median')
    for i, k in enumerate(k_values):
        th = thresholds[k]
        ax2.axvline(th, color=colors[i], linestyle='--', label=f'k={k}')

    ax2.set_title('Distribution of Log Bayes Factor')
    ax2.set_xlabel('Log Bayes Factor')
    ax2.set_ylabel('Density')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path)
    print(f"\nâœ… åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")

    print("\n" + "=" * 60)
    print("ğŸ“Š æ¨èé˜ˆå€¼è®¾ç½®å‚è€ƒ (åŸºäº Median - k * MAD):")
    print(f"Median Log BF: {median:.4f}")
    print(f"MAD: {mad:.4f}")
    print("-" * 40)
    for k in k_values:
        val = thresholds[k]
        # é…ç½®æ–‡ä»¶ä¸­ BNDMDetector ä¼šå¯¹ threshold å– log
        # self.threshold = math.log(config.get('threshold', 0.05))
        # å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ› Log BF çš„é˜ˆå€¼æ˜¯ valï¼Œé‚£ä¹ˆ Config ä¸­çš„å€¼åº”è¯¥æ˜¯ exp(val)
        prob_val = np.exp(val)
        print(f"k = {k:2d} | å»ºè®® Log Threshold: {val:.4f} | å¯¹åº” Config Threshold (å¡«å…¥yaml): {prob_val:.4e}")
    print("=" * 60)
    print("ğŸ’¡ æç¤º: ")
    print("1. è¾ƒå°çš„ k (å¦‚ k=3) -> æ›´æ•æ„Ÿ (More Drifts)")
    print("2. è¾ƒå¤§çš„ k (å¦‚ k=10) -> æ›´ç¨³å¥ (Less False Alarms)")
    print("3. è¯·å°† 'Config Threshold' çš„å€¼å¤åˆ¶åˆ° run_experiment.py æˆ–é…ç½®æ–‡ä»¶ä¸­ã€‚")


def main():
    parser = argparse.ArgumentParser(description="Determine BNDM Drift Threshold using MAD")
    parser.add_argument("--config_name", type=str, default="flow_bert_multiview_config", help="Config name")
    parser.add_argument("--dataset_name", type=str, default="cic_ids_2017", help="Dataset name")
    args = parser.parse_args()

    # 1. åŠ è½½é…ç½®
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.abspath(os.path.join(current_dir, "../../"))

    config_path = os.path.join(project_root, "src/models/flow_bert_multiview/config")

    # åŠ è½½ä¸»é…ç½®
    cfg = OmegaConf.load(os.path.join(config_path, f"{args.config_name}.yaml"))

    # åŠ è½½æ•°æ®é›†é…ç½®
    dataset_yaml_path = os.path.join(config_path, f"datasets/{args.dataset_name}.yaml")
    if os.path.exists(dataset_yaml_path):
        print(f"Loading dataset config from: {dataset_yaml_path}")
        dataset_cfg = OmegaConf.load(dataset_yaml_path)

        # =========================================================================
        # ğŸ”´ æ ¸å¿ƒä¿®æ­£ï¼šæ„å»º cfg.datasets.labels ç»“æ„
        # =========================================================================
        if 'datasets' not in cfg:
            cfg.datasets = OmegaConf.create()

        # å°†æ•´ä¸ª dataset_cfg æŒ‚è½½åˆ° cfg.datasets ä¸‹
        # è¿™æ · cfg.datasets.labels å°±èƒ½è¢«è®¿é—®åˆ°äº†
        # åŒæ—¶ä¿ç•™ dataset_cfg ä¸­çš„å…¶ä»–å­—æ®µ (å¦‚ flow_data_path)
        cfg.datasets = OmegaConf.merge(cfg.datasets, dataset_cfg)

        # ä¸ºäº†å…¼å®¹æ€§ï¼Œä¹Ÿå¯ä»¥å°† dataset_cfg çš„å†…å®¹ç›´æ¥ merge åˆ° data ä¸‹ (æ—§é€»è¾‘)
        if 'data' not in cfg:
            cfg.data = OmegaConf.create()
        cfg.data = OmegaConf.merge(cfg.data, dataset_cfg)

        # è§£æè·¯å¾„
        if 'flow_data_path' in dataset_cfg:
            cfg.data.flow_data_path = resolve_path(dataset_cfg.flow_data_path, dataset_cfg.name)
        if 'session_split_path' in dataset_cfg:
            cfg.data.session_split.session_split_path = resolve_path(dataset_cfg.session_split_path, dataset_cfg.name)

        cfg.data.dataset = dataset_cfg.name

    else:
        print(f"Dataset config not found: {dataset_yaml_path}")
        return

    # =========================================================================
    # ğŸ”´ å…³é”®é€»è¾‘ 1: ç¡®ä¿ä½¿ç”¨åŒ…å«ç‰¹å¾çš„ all_embedded_flow.csv
    # =========================================================================
    original_path = cfg.data.flow_data_path
    if "all_flow.csv" in original_path:
        # å°è¯•åˆ‡æ¢åˆ° embedded æ–‡ä»¶
        target_path = original_path.replace("all_flow.csv", "all_embedded_flow.csv")
        if os.path.exists(target_path):
            print(f"ğŸ”´ [Auto-Correction] æ£€æµ‹åˆ° all_flow.csv (ç¼ºç‰¹å¾)ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸º: {target_path}")
            cfg.data.flow_data_path = target_path
        else:
            print(f"âš ï¸ [Warning] æ— æ³•æ‰¾åˆ° all_embedded_flow.csvï¼Œç»§ç»­ä½¿ç”¨: {original_path}")
            print("   å¯èƒ½ä¼šå› ç¼ºå°‘ ssl.server_name*_freq ç­‰åˆ—è€ŒæŠ¥é”™ï¼")

    # =========================================================================
    # ğŸ”´ å…³é”®é€»è¾‘ 2: å¼ºåˆ¶æŒ‰é¡ºåºè¯»å– (ä¸éšæœºæ‰“ä¹±)
    # =========================================================================
    print("ğŸ”´ [Config] å¼ºåˆ¶è®¾ç½® split_mode = 'flow' (æ—¶åºæ¨¡å¼)")
    cfg.data.split_mode = "flow"

    print("ğŸ”´ [Config] å¼ºåˆ¶ç¦ç”¨éšæœºé‡‡æ · (random = False)")
    if 'sampling' not in cfg.data:
        cfg.data.sampling = {}
    cfg.data.sampling.random = False

    # 2. åˆå§‹åŒ–æ•°æ®æ¨¡å—
    print("æ­£åœ¨åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨...")
    dm = MultiviewFlowDataModule(cfg)
    dm.setup(stage="fit")

    # ä½¿ç”¨éªŒè¯é›†è¿›è¡Œé˜ˆå€¼ç¡®å®š (ä½äºè®­ç»ƒé›†ä¹‹åï¼Œé€‚åˆæµ‹è¯•)
    target_loader = dm.val_dataloader()
    if not target_loader:
        print("éªŒè¯é›†åŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æµ‹è¯•é›†...")
        target_loader = dm.test_dataloader()

    # è·å–æ˜ å°„ (ç”¨äºæ¨¡å‹åˆå§‹åŒ–)
    if hasattr(dm, 'train_dataset') and dm.train_dataset:
        mappings = getattr(dm.train_dataset, 'categorical_val2idx_mappings', None)
        effective_columns = getattr(dm.train_dataset, 'categorical_columns_effective', None)
    else:
        # å…œåº•åˆå§‹åŒ–
        _ = dm.train_dataloader()
        mappings = getattr(dm.train_dataset, 'categorical_val2idx_mappings', None)
        effective_columns = getattr(dm.train_dataset, 'categorical_columns_effective', None)

    dataset_wrapper = MappingWrapper(mappings, effective_columns)

    # 3. åŠ è½½æ¨¡å‹
    ckpt_path = find_valid_checkpoint(project_root)
    if not ckpt_path:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ¨¡å‹æ£€æŸ¥ç‚¹ (Checkpoint)ï¼è¯·å…ˆè¿è¡Œè®­ç»ƒã€‚")
        return

    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {ckpt_path}")
    try:
        model = FlowBertMultiview.load_from_checkpoint(ckpt_path, cfg=cfg, dataset=dataset_wrapper)
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return

    # 4. è¿è¡Œåˆ†æ
    log_bfs = analyze_threshold(model, target_loader)

    # 5. ç»˜å›¾å’Œè¾“å‡º
    plot_analysis(log_bfs, save_path=os.path.join(project_root, "drift_threshold_analysis.png"))


if __name__ == "__main__":
    main()