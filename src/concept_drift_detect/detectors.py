import torch
import numpy as np
import math
from abc import ABC, abstractmethod
from collections import deque
from typing import Dict, List, Optional

# å°è¯•å¯¼å…¥ river ç”¨äºå¯¹æ¯”å®éªŒ
try:
    from river import drift

    RIVER_AVAILABLE = True
except ImportError:
    RIVER_AVAILABLE = False


# ==========================================
# æ ¸å¿ƒæ•°å­¦å·¥å…·
# ==========================================
def log_beta(a, b):
    """è®¡ç®— log(Beta(a, b))"""
    return math.lgamma(a) + math.lgamma(b) - math.lgamma(a + b)


# ğŸ”´ [Removed] log_binomial å‡½æ•°å·²ç§»é™¤ï¼Œå› ä¸º BNDM å¤„ç†åºåˆ—ä¼¼ç„¶ä¸éœ€è¦ç»„åˆæ•°


# ==========================================
# æ£€æµ‹å™¨åŸºç±»
# ==========================================
class BaseDriftDetector(ABC):
    def __init__(self, config: Dict):
        self.config = config
        self.total_samples = 0

        # é¢„å¤„ç†ï¼šéšæœºæŠ•å½±çŸ©é˜µ
        self.projection_matrix = None
        self.running_mean = 0.0
        self.running_var = 1.0

        # æ˜¯å¦å†»ç»“ç»Ÿè®¡é‡ (ç”¨äºå›ºå®šå‚è€ƒç³»)
        self.stats_frozen = False

    def preprocess(self, features: torch.Tensor) -> float:
        """
        ç‰¹å¾é™ç»´ + åœ¨çº¿å½’ä¸€åŒ–
        Args:
            features: Tensor of shape (1, Dim) or (Dim,)
        Returns:
            Scalar float value (projected and normalized)
        """
        device = features.device

        # ç¡®ä¿è¾“å…¥æ˜¯ (1, Dim)
        if features.dim() == 1:
            features = features.unsqueeze(0)

        # è·å–ç‰¹å¾ç»´åº¦
        feature_dim = features.shape[-1]

        # åˆå§‹åŒ–æŠ•å½±çŸ©é˜µ (Dim, 1)
        if self.projection_matrix is None:
            g_cpu = torch.Generator()
            g_cpu.manual_seed(self.config.get('seed', 2026))

            # åˆ›å»º (Feature_Dim, 1) çš„çŸ©é˜µ
            self.projection_matrix = torch.randn(feature_dim, 1, generator=g_cpu).to(device)
            self.projection_matrix = self.projection_matrix / torch.norm(self.projection_matrix)
        elif self.projection_matrix.device != device:
            self.projection_matrix = self.projection_matrix.to(device)

        # æŠ•å½±: (1, Dim) x (Dim, 1) -> (1, 1)
        val = torch.matmul(features, self.projection_matrix).item()

        # ä»…åœ¨æœªå†»ç»“æ—¶æ›´æ–°ç»Ÿè®¡é‡ï¼Œé˜²æ­¢æ¼‚ç§»è¢«åœ¨çº¿å½’ä¸€åŒ–æ©ç›–
        if not self.stats_frozen:
            self.total_samples += 1
            delta = val - self.running_mean
            self.running_mean += delta / self.total_samples
            delta2 = val - self.running_mean
            self.running_var += delta * delta2

        if self.total_samples < 2:
            return 0.0

        std = math.sqrt(self.running_var / (self.total_samples - 1)) + 1e-8
        return (val - self.running_mean) / std

    def freeze_stats(self):
        """å†»ç»“å½’ä¸€åŒ–å‚æ•° (Reference Window ç¡®å®šåè°ƒç”¨)"""
        self.stats_frozen = True

    @abstractmethod
    def update(self, val: float) -> bool:
        pass

    @abstractmethod
    def reset(self):
        pass


# ==========================================
# BNDM (Polya Tree) å®ç°
# ==========================================
class PTNode:
    def __init__(self, level, alpha):
        self.level = level
        self.alpha = alpha
        self.n_ref_L = 0
        self.n_ref_R = 0
        self.n_cur_L = 0
        self.n_cur_R = 0
        self.cached_log_B = 0.0
        self.left = None
        self.right = None

    def compute_log_bayes_factor(self):
        """
        è®¡ç®— Log Bayes Factor.
        æ³¨æ„ï¼šæ­¤å¤„æ¯”è¾ƒçš„æ˜¯åºåˆ—æ•°æ®çš„ç”Ÿæˆæ¦‚ç‡ï¼Œå› æ­¤ä¸åŒ…å«äºŒé¡¹å¼ç»„åˆç³»æ•°ã€‚
        """
        n_ref = self.n_ref_L + self.n_ref_R
        n_cur = self.n_cur_L + self.n_cur_R

        # è¾¹ç•Œæƒ…å†µ
        if n_ref == 0 and n_cur == 0:
            self.cached_log_B = 0.0
            return 0.0

        n_tot_L = self.n_ref_L + self.n_cur_L
        n_tot_R = self.n_ref_R + self.n_cur_R

        # H0: åŒåˆ†å¸ƒ (Combined)
        # Log Probability = Log Beta(alpha + n_L, alpha + n_R) - Log Beta(alpha, alpha)
        log_ev_H0 = log_beta(self.alpha + n_tot_L, self.alpha + n_tot_R) - \
                    log_beta(self.alpha, self.alpha)

        # H1: ä¸åŒåˆ†å¸ƒ (Separate)
        # Log Probability = (Log Beta_Ref + Log Beta_Cur)
        log_ev_H1_ref = log_beta(self.alpha + self.n_ref_L, self.alpha + self.n_ref_R) - \
                        log_beta(self.alpha, self.alpha)

        log_ev_H1_cur = log_beta(self.alpha + self.n_cur_L, self.alpha + self.n_cur_R) - \
                        log_beta(self.alpha, self.alpha)

        # Log Bayes Factor = Log P(H0) - Log P(H1)
        # è´Ÿå€¼è¶Šå°ï¼Œè¶Šå€¾å‘äº H1 (Drift)
        self.cached_log_B = log_ev_H0 - (log_ev_H1_ref + log_ev_H1_cur)
        return self.cached_log_B


class BNDMDetector(BaseDriftDetector):
    def __init__(self, config: Dict):
        super().__init__(config)
        self.max_level = config.get('max_level', 5)
        self.alpha_scale = config.get('alpha_scale', 0.1)
        self.window_size = config.get('window_size', 1000)
        # BNDM ä½¿ç”¨ log Bayes Factor
        # å¦‚æœ threshold = 0.05, math.log(0.05) â‰ˆ -3.0
        self.threshold = math.log(config.get('threshold', 0.05))

        self.ref_window = deque(maxlen=self.window_size)
        self.cur_window = deque(maxlen=self.window_size)
        self.root = self._build_tree(0)

        from scipy.stats import norm
        self.norm_cdf = norm.cdf
        self.is_initialized = False

    def _build_tree(self, level):
        # æŒ‰ç…§ BNDM è®ºæ–‡å»ºè®®ï¼Œalpha éšæ·±åº¦å¢åŠ ï¼Œä»¥ä¿æŒä¸åŒå±‚çº§çš„å½±å“åŠ›å¹³è¡¡
        alpha = self.alpha_scale * ((level + 1) ** 2)
        node = PTNode(level, alpha)
        if level < self.max_level:
            node.left = self._build_tree(level + 1)
            node.right = self._build_tree(level + 1)
        return node

    def _update_tree(self, val, window_type, delta=1):
        # å°†æ ‡å‡†åŒ–åçš„å€¼æ˜ å°„åˆ° [0, 1] åŒºé—´
        cdf = self.norm_cdf(val)
        node = self.root
        low, high = 0.0, 1.0

        for _ in range(self.max_level):
            mid = (low + high) / 2
            if cdf < mid:
                if window_type == 'ref':
                    node.n_ref_L += delta
                else:
                    node.n_cur_L += delta

                # å®æ—¶æ›´æ–°å½“å‰èŠ‚ç‚¹ BF
                node.compute_log_bayes_factor()
                node = node.left
                high = mid
            else:
                if window_type == 'ref':
                    node.n_ref_R += delta
                else:
                    node.n_cur_R += delta

                # å®æ—¶æ›´æ–°å½“å‰èŠ‚ç‚¹ BF
                node.compute_log_bayes_factor()
                node = node.right
                low = mid

    def _get_total_bf(self):
        total = 0.0
        q = [self.root]
        while q:
            node = q.pop(0)
            total += node.cached_log_B
            if node.left: q.append(node.left)
            if node.right: q.append(node.right)
        return total

    def update(self, val: float) -> bool:
        # 1. åˆå§‹åŒ–é˜¶æ®µ (å¡«å…… Reference Window)
        if not self.is_initialized:
            self.cur_window.append(val)
            if len(self.cur_window) >= self.window_size:
                # å°†æ”¶é›†åˆ°çš„æ•°æ®ä½œä¸º Reference
                for v in self.cur_window:
                    self.ref_window.append(v)
                    self._update_tree(v, 'ref', 1)

                # åˆå§‹åŒ–å®Œæˆåï¼Œå†»ç»“å½’ä¸€åŒ–ç»Ÿè®¡é‡
                # è¿™ç¡®ä¿åç»­çš„æ¼‚ç§»æ•°æ®åœ¨åæ ‡ç³»ä¸­å‘ˆç°åç§»ï¼Œè€Œä¸æ˜¯è¢«å½’ä¸€åŒ–æ¶ˆé™¤
                self.freeze_stats()

                # æ¸…ç©ºå½“å‰çª—å£ï¼Œå‡†å¤‡å¼€å§‹ç›‘æµ‹
                self.cur_window.clear()
                self.is_initialized = True
            return False

        # 2. æ»‘åŠ¨çª—å£ç»´æŠ¤
        if len(self.cur_window) == self.window_size:
            old_val = self.cur_window.popleft()
            self._update_tree(old_val, 'cur', -1)

        self.cur_window.append(val)
        self._update_tree(val, 'cur', 1)

        # Warm-up: å¦‚æœå½“å‰çª—å£æ ·æœ¬å¤ªå°‘ï¼Œç»Ÿè®¡é‡ä¸ç¨³å®šï¼Œè·³è¿‡æ£€æµ‹
        if len(self.cur_window) < 50:
            return False

        log_bf = self._get_total_bf()
        return log_bf < self.threshold

    def reset(self):
        self.root = self._build_tree(0)
        self.ref_window.clear()

        # å°†å½“å‰çš„æ»‘åŠ¨çª—å£ä½œä¸ºæ–°çš„å‚è€ƒçª—å£
        for v in self.cur_window:
            self.ref_window.append(v)
            self._update_tree(v, 'ref', 1)

        # ä¿æŒç»Ÿè®¡é‡å†»ç»“çŠ¶æ€ (ä½¿ç”¨å½“å‰çš„åæ ‡ç³»ç»§ç»­ç›‘æµ‹)
        self.freeze_stats()

        self.cur_window.clear()


class ADWINDetector(BaseDriftDetector):
    def __init__(self, config: Dict):
        super().__init__(config)
        if not RIVER_AVAILABLE:
            raise ImportError("River library required for ADWIN")
        self.adwin = drift.ADWIN(delta=config.get('delta', 0.002))

    def update(self, val: float) -> bool:
        self.adwin.update(val)
        return self.adwin.drift_detected

    def reset(self):
        self.adwin = drift.ADWIN(delta=self.config.get('delta', 0.002))