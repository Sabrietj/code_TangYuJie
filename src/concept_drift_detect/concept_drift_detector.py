import torch
import numpy as np
import logging
from typing import Dict, List, Tuple, Any, Optional
from collections import deque
import math
from abc import ABC, abstractmethod
from scipy.special import betaln
from scipy.stats import norm

# å°è¯•å¯¼å…¥ riverï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æŠ¥é”™æˆ–é™çº§
try:
    from river import drift

    RIVER_AVAILABLE = True
except ImportError:
    RIVER_AVAILABLE = False

logger = logging.getLogger(__name__)


# ==========================================
# 1. æŠ½è±¡åŸºç±» (Interface)
# ==========================================

class BaseDriftDetector(ABC):
    """æ¦‚å¿µæ¼‚ç§»æ£€æµ‹å™¨æŠ½è±¡åŸºç±»"""

    def __init__(self, config: Dict):
        self.config = config
        self.drift_count = 0
        self.total_samples = 0
        self.is_initialized = False

        # ç‰¹å¾é¢„å¤„ç†çŠ¶æ€
        self.running_mean = 0.0
        self.running_var = 1.0
        self.projection_matrix = None

    def preprocess(self, features: torch.Tensor) -> List[float]:
        """
        é€šç”¨é¢„å¤„ç†ï¼šéšæœºæŠ•å½± -> åœ¨çº¿å½’ä¸€åŒ– -> è½¬æ ‡é‡åˆ—è¡¨
        """
        batch_size = features.shape[0]
        feature_dim = features.shape[1]
        device = features.device

        # åˆå§‹åŒ–æŠ•å½±çŸ©é˜µ
        if self.projection_matrix is None:
            self.projection_matrix = torch.randn(feature_dim, 1).to(device)
            self.projection_matrix = self.projection_matrix / torch.norm(self.projection_matrix)
        elif self.projection_matrix.device != device:
            self.projection_matrix = self.projection_matrix.to(device)

        # 1. æŠ•å½±
        projected = torch.matmul(features, self.projection_matrix).squeeze(-1)  # [B]

        z_vals = []
        for val in projected:
            val_item = val.item()
            self.total_samples += 1

            # 2. åœ¨çº¿æ›´æ–° Mean/Var
            delta = val_item - self.running_mean
            self.running_mean += delta / self.total_samples
            delta2 = val_item - self.running_mean
            self.running_var += delta * delta2

            # 3. å½’ä¸€åŒ– (Z-Score)
            if self.total_samples < 2:
                z = 0.0
            else:
                std = math.sqrt(self.running_var / (self.total_samples - 1)) + 1e-8
                z = (val_item - self.running_mean) / std

            z_vals.append(z)

        return z_vals

    @abstractmethod
    def update(self, val: float) -> bool:
        """æ›´æ–°å•ä¸ªæ ·æœ¬ï¼Œè¿”å›æ˜¯å¦æ¼‚ç§»"""
        pass

    @abstractmethod
    def get_info(self) -> Dict:
        """è¿”å›å½“å‰çŠ¶æ€ä¿¡æ¯ï¼ˆå¦‚ BayesFactor æˆ– Window Sizeï¼‰"""
        pass

    @abstractmethod
    def get_drift_evidence(self) -> str:
        """è·å–æ¼‚ç§»è¯æ®æè¿°ï¼ˆç”¨äºæ—¥å¿—ï¼‰"""
        pass

    @abstractmethod
    def reset(self):
        """é‡ç½®æ£€æµ‹å™¨çŠ¶æ€"""
        pass


class PTNode:
    """Polya Tree èŠ‚ç‚¹ (ä¿æŒä¸å˜)"""

    def __init__(self, level: int, code: str, alpha_val: float):
        self.level = level
        self.code = code
        self.alpha_0 = alpha_val
        self.alpha_1 = alpha_val
        self.n_ref_0 = 0
        self.n_ref_1 = 0
        self.n_cur_0 = 0
        self.n_cur_1 = 0
        self.cached_log_B_s = 0.0
        self.left: Optional['PTNode'] = None
        self.right: Optional['PTNode'] = None

    def update_counts(self, side: int, window_type: str, delta: int = 1):
        if window_type == 'ref':
            if side == 0:
                self.n_ref_0 += delta
            else:
                self.n_ref_1 += delta
        else:
            if side == 0:
                self.n_cur_0 += delta
            else:
                self.n_cur_1 += delta

    def compute_log_local_bayes_factor(self) -> float:
        N_tot_0 = self.n_ref_0 + self.n_cur_0
        N_tot_1 = self.n_ref_1 + self.n_cur_1
        a0 = self.alpha_0
        a1 = self.alpha_1
        log_prob_H0 = betaln(a0 + N_tot_0, a1 + N_tot_1) - betaln(a0, a1)
        log_prob_H1_ref = betaln(a0 + self.n_ref_0, a1 + self.n_ref_1) - betaln(a0, a1)
        log_prob_H1_cur = betaln(a0 + self.n_cur_0, a1 + self.n_cur_1) - betaln(a0, a1)
        self.cached_log_B_s = log_prob_H0 - (log_prob_H1_ref + log_prob_H1_cur)
        return self.cached_log_B_s

    def get_counts_info(self) -> str:
        return f"Ref[L:{self.n_ref_0}, R:{self.n_ref_1}] vs Cur[L:{self.n_cur_0}, R:{self.n_cur_1}]"


class PolyaTree:
    """Polya Tree ç»“æ„ (ä¿æŒä¸å˜)"""

    def __init__(self, max_level: int = 4, c: float = 1.0):
        self.max_level = max_level
        self.c = c
        self.root = self._build_tree(0, "")

    def _build_tree(self, level: int, code: str) -> PTNode:
        alpha = self.c * ((level + 1) ** 2)
        node = PTNode(level, code, alpha)
        if level < self.max_level:
            node.left = self._build_tree(level + 1, code + "0")
            node.right = self._build_tree(level + 1, code + "1")
        return node

    def _get_direction(self, val: float, level: int, code: str) -> int:
        val_int = 0
        if len(code) > 0: val_int = int(code, 2)
        total_intervals = 2 ** level
        step = 1.0 / total_intervals
        start_p = val_int * step
        mid_p = start_p + step / 2.0
        cut_point = norm.ppf(mid_p)
        return 0 if val < cut_point else 1

    def update(self, val: float, window_type: str, delta: int = 1):
        curr = self.root
        curr_code = ""
        for level in range(self.max_level + 1):
            if curr is None: break
            direction = self._get_direction(val, level, curr_code)
            curr.update_counts(direction, window_type, delta)
            curr.compute_log_local_bayes_factor()
            if direction == 0:
                curr = curr.left
                curr_code += "0"
            else:
                curr = curr.right
                curr_code += "1"

    def compute_total_bayes_factor(self) -> float:
        total_log_B = 0.0
        queue = deque([self.root])
        while queue:
            node = queue.popleft()
            total_log_B += node.cached_log_B_s
            if node.left: queue.append(node.left)
            if node.right: queue.append(node.right)
        return total_log_B

    def diagnose_drift(self, top_k: int = 3) -> List[Dict]:
        all_nodes = []
        queue = deque([self.root])
        while queue:
            node = queue.popleft()
            total_count = node.n_ref_0 + node.n_ref_1 + node.n_cur_0 + node.n_cur_1
            if total_count > 0: all_nodes.append(node)
            if node.left: queue.append(node.left)
            if node.right: queue.append(node.right)
        sorted_nodes = sorted(all_nodes, key=lambda x: x.cached_log_B_s)
        diagnosis = []
        for node in sorted_nodes[:top_k]:
            diagnosis.append({
                "level": node.level,
                "code": node.code if node.code else "ROOT",
                "log_B_s": node.cached_log_B_s,
                "ref_counts": (node.n_ref_0, node.n_ref_1),
                "cur_counts": (node.n_cur_0, node.n_cur_1),
                "description": node.get_counts_info()
            })
        return diagnosis

    def reset_counts(self):
        queue = deque([self.root])
        while queue:
            node = queue.popleft()
            node.n_ref_0 = 0;
            node.n_ref_1 = 0;
            node.n_cur_0 = 0;
            node.n_cur_1 = 0
            node.cached_log_B_s = 0.0
            if node.left: queue.append(node.left)
            if node.right: queue.append(node.right)


# --- BNDM Detector ---
class BNDMDetector(BaseDriftDetector):
    def __init__(self, config: Dict):
        super().__init__(config)
        self.params = config.get('detectors', {}).get('bndm', {})

        self.pt = PolyaTree(
            max_level=self.params.get('max_tree_level', 4),
            c=self.params.get('polya_c', 1.0)
        )
        self.window_size = self.params.get('window_size', 500)
        self.threshold = self.params.get('threshold', 0.15)
        self.min_samples = self.params.get('min_samples', 100)

        self.ref_window = deque(maxlen=self.window_size)
        self.cur_window = deque(maxlen=self.window_size)
        self.last_B = 1.0

    def update(self, val: float) -> bool:
        # åˆå§‹åŒ–é˜¶æ®µ
        if not self.is_initialized:
            self.cur_window.append(val)
            if len(self.cur_window) >= self.min_samples:
                # åˆå§‹åŒ–å®Œæˆï¼šCur -> Ref
                self.pt.reset_counts()
                self.ref_window.clear()
                for v in self.cur_window:
                    self.ref_window.append(v)
                    self.pt.update(v, 'ref', 1)
                    self.pt.update(v, 'cur', 1)
                self.is_initialized = True
            return False

        # è¿è¡Œé˜¶æ®µ
        if len(self.cur_window) == self.window_size:
            old_val = self.cur_window.popleft()
            self.pt.update(old_val, 'cur', -1)

        self.cur_window.append(val)
        self.pt.update(val, 'cur', 1)

        # è®¡ç®— Bayes Factor
        log_B = self.pt.compute_total_bayes_factor()
        try:
            self.last_B = math.exp(log_B)
        except OverflowError:
            self.last_B = float('inf') if log_B > 0 else 0.0

        is_drift = log_B < math.log(self.threshold)

        if is_drift:
            self.drift_count += 1

        return is_drift

    def reset(self):
        # BNDM çš„ reset é€šå¸¸æ˜¯æŠŠ Cur è®¾ä¸º Ref
        self.pt.reset_counts()
        self.ref_window.clear()
        data_list = list(self.cur_window)
        for val in data_list:
            self.ref_window.append(val)
            self.pt.update(val, 'ref', 1)
            self.pt.update(val, 'cur', 1)
        # æ³¨æ„ï¼šè¿™é‡Œ cur_window ä¸æ¸…ç©ºï¼Œè€Œæ˜¯ç»§ç»­æ»‘åŠ¨ï¼Œæˆ–è€…æ ¹æ®ç­–ç•¥æ¸…ç©º

    def get_info(self) -> Dict:
        return {
            "bayes_factor": self.last_B,
            "ref_size": len(self.ref_window),
            "cur_size": len(self.cur_window)
        }

    def get_drift_evidence(self) -> str:
        return f"Bayes Factor {self.last_B:.6e} < Threshold {self.threshold}"


# --- ADWIN Detector ---
class ADWINDetector(BaseDriftDetector):
    def __init__(self, config: Dict):
        super().__init__(config)
        if not RIVER_AVAILABLE:
            raise ImportError("River library not installed. Cannot use ADWIN.")

        self.params = config.get('detectors', {}).get('adwin', {})
        self.adwin = drift.ADWIN(
            delta=self.params.get('delta', 0.002),
            clock=self.params.get('clock', 32)
        )
        self.width = 0
        self.variance = 0.0
        self.is_initialized = True  # ADWIN ä¸éœ€è¦æ˜¾å¼åˆå§‹åŒ–é˜¶æ®µ

    def update(self, val: float) -> bool:
        self.adwin.update(val)
        self.width = self.adwin.width
        self.variance = self.adwin.variance

        if self.adwin.drift_detected:
            self.drift_count += 1
            return True
        return False

    def reset(self):
        # ADWIN è‡ªåŠ¨å¤„ç†çª—å£é‡ç½®ï¼Œæ‰‹åŠ¨ reset æ„å‘³ç€å®Œå…¨é‡æ¥
        self.adwin = drift.ADWIN(
            delta=self.params.get('delta', 0.002),
            clock=self.params.get('clock', 32)
        )

    def get_info(self) -> Dict:
        return {
            "width": self.width,
            "variance": self.variance
        }

    def get_drift_evidence(self) -> str:
        return f"ADWIN Width Shrink detected. Variance: {self.variance:.4f}"


# ==========================================
# 3. é€‚åº”ç­–ç•¥ç®¡ç†å™¨ (Adaptation Manager)
# ==========================================

class DriftAdaptationManager:
    """ç®¡ç†å½“æ¼‚ç§»å‘ç”Ÿæ—¶çš„é€‚åº”ç­–ç•¥"""

    def __init__(self, config: Dict, pl_module):
        self.config = config.get('adaptation', {})
        self.pl_module = pl_module
        self.logger = logging.getLogger("DriftAdaptation")

    def adapt(self, detector: BaseDriftDetector):
        """æ‰§è¡Œé…ç½®çš„æ‰€æœ‰é€‚åº”ç­–ç•¥"""
        actions_taken = []

        # 1. å­¦ä¹ ç‡è¡°å‡
        if self.config.get('lr_decay', {}).get('enabled', False):
            factor = self.config['lr_decay'].get('factor', 0.5)
            min_lr = float(self.config['lr_decay'].get('min_lr', 1e-7))

            optimizers = self.pl_module.trainer.optimizers
            for opt in optimizers:
                for param_group in opt.param_groups:
                    old_lr = param_group['lr']
                    new_lr = max(old_lr * factor, min_lr)
                    param_group['lr'] = new_lr

            actions_taken.append(f"LR Decay ({factor}x)")

        # 2. ä¼˜åŒ–å™¨é‡ç½® (æ¸…é™¤åŠ¨é‡)
        if self.config.get('optimizer_reset', {}).get('enabled', False):
            optimizers = self.pl_module.trainer.optimizers
            for opt in optimizers:
                if hasattr(opt, 'state'):
                    opt.state.clear()  # æ¸…ç©º state (å¦‚ Adam çš„ m, v)
            actions_taken.append("Optimizer Momentum Reset")

        # 3. æ£€æµ‹å™¨é‡ç½® (Window Reset)
        if self.config.get('window_reset', {}).get('enabled', False):
            detector.reset()
            actions_taken.append("Detector Window Reset")

        self.logger.info(f"ğŸ›¡ï¸ æ¼‚ç§»é€‚åº”æ‰§è¡Œ: {', '.join(actions_taken)}")


# ==========================================
# 4. å·¥å‚ç±»
# ==========================================

class DriftDetectorFactory:
    @staticmethod
    def create(config: Dict, algorithm: str) -> BaseDriftDetector:
        if algorithm == "bndm":
            return BNDMDetector(config)
        elif algorithm == "adwin":
            return ADWINDetector(config)
        # elif algorithm == "ks": return KSDetector(config)
        else:
            raise ValueError(f"Unknown drift algorithm: {algorithm}")


# ==========================================
# 5. æ£€æµ‹å™¨ç®¡ç†å™¨ (å¤„ç†ä¸»/å½±æ¨¡å¼)
# ==========================================

class ConceptDriftManager:
    """æ•´åˆæ‰€æœ‰é€»è¾‘çš„å…¥å£"""

    def __init__(self, cfg, pl_module):
        self.drift_cfg = cfg.concept_drift
        self.adapter = DriftAdaptationManager(self.drift_cfg, pl_module)

        # ä¸»æ£€æµ‹å™¨
        self.main_detector = DriftDetectorFactory.create(self.drift_cfg, self.drift_cfg.algorithm)
        self.main_name = self.drift_cfg.algorithm

        # å½±å­æ£€æµ‹å™¨ (ç”¨äºå¯¹æ¯”)
        self.shadow_detectors = {}
        if self.drift_cfg.get('shadow_mode', {}).get('enabled', False):
            for name in self.drift_cfg.shadow_mode.algorithms:
                if name != self.main_name:
                    self.shadow_detectors[name] = DriftDetectorFactory.create(self.drift_cfg, name)

        self.history = []

    def process_batch(self, features: torch.Tensor, global_step: int, current_epoch: int) -> Dict:
        """å¤„ç†ä¸€ä¸ªBatchçš„æ•°æ®"""
        # 1. é¢„å¤„ç† (ä½¿ç”¨ä¸»æ£€æµ‹å™¨çš„é¢„å¤„ç†é€»è¾‘ï¼Œä¿è¯ä¸€è‡´æ€§)
        z_vals = self.main_detector.preprocess(features)

        # 2. æ›´æ–°ä¸»æ£€æµ‹å™¨
        main_drift = False
        # æ‰¹é‡æ›´æ–°ï¼ˆè™½ç„¶ BNDM æ”¯æŒæµå¼ï¼Œä½†åœ¨ Batch Loop ä¸­å¾ªç¯è°ƒç”¨ï¼‰
        # ä¸ºäº†æ€§èƒ½ï¼Œå¯ä»¥æŠ½æ ·ã€‚è¿™é‡Œå…¨é‡æ›´æ–°ã€‚
        for z in z_vals:
            if self.main_detector.update(z):
                main_drift = True
                # æ³¨æ„ï¼šæœ‰äº›æ£€æµ‹å™¨ï¼ˆå¦‚ADWINï¼‰æ˜¯æ¯ä¸ªç‚¹éƒ½å¯èƒ½è§¦å‘ï¼Œ
                # è¿™é‡Œæˆ‘ä»¬æ ‡è®°è¯¥ Batch å‘ç”Ÿäº†æ¼‚ç§»

        # 3. æ›´æ–°å½±å­æ£€æµ‹å™¨
        shadow_drifts = {}
        for name, det in self.shadow_detectors.items():
            triggered = False
            for z in z_vals:
                if det.update(z):
                    triggered = True
            shadow_drifts[name] = triggered

        # 4. è§¦å‘é€‚åº” (ä»…ç”±ä¸»æ£€æµ‹å™¨å†³å®š)
        if main_drift:
            self.adapter.adapt(self.main_detector)
            # ä¹Ÿå¯ä»¥é€‰æ‹©æ˜¯å¦é‡ç½®å½±å­æ£€æµ‹å™¨ï¼Œé€šå¸¸ä¸é‡ç½®ä»¥è§‚å¯Ÿå®ƒä»¬æ˜¯å¦éšåè§¦å‘

        # 5. è®°å½•å†å²
        if main_drift or any(shadow_drifts.values()):
            record = {
                "step": global_step,
                "epoch": current_epoch,
                "main_algo": self.main_name,
                "main_triggered": main_drift,
                "main_info": self.main_detector.get_info(),
                "shadow_status": shadow_drifts
            }
            self.history.append(record)

        return {
            "main_drift": main_drift,
            "info": self.main_detector.get_info()
        }

    def generate_report(self):
        """ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š æ¦‚å¿µæ¼‚ç§»æ£€æµ‹å™¨å¯¹æ¯”æŠ¥å‘Š")
        report.append(f"ä¸»ç®—æ³• (Active): {self.main_name.upper()} | è§¦å‘æ¬¡æ•°: {self.main_detector.drift_count}")

        for name, det in self.shadow_detectors.items():
            report.append(f"å½±ç®—æ³• (Passive): {name.upper()} | è§¦å‘æ¬¡æ•°: {det.drift_count}")

        report.append("-" * 60)
        report.append(f"{'Step':<10} | {'Epoch':<6} | {self.main_name.upper():<10} | {'Shadow Algos'}")

        for rec in self.history:
            main_mark = "ğŸ”´ DRIFT" if rec['main_triggered'] else "   -"
            shadow_marks = [f"{k}:{'ğŸ”µ' if v else '-'}" for k, v in rec['shadow_status'].items()]
            report.append(f"{rec['step']:<10} | {rec['epoch']:<6} | {main_mark:<10} | {', '.join(shadow_marks)}")

        report.append("=" * 60)
        return "\n".join(report)