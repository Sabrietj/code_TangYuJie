import pandas as pd
import numpy as np
import os
import ast
import sys
from tqdm import tqdm
from datetime import datetime

# ================= é…ç½®åŒºåŸŸ =================
# è¯·æ ¹æ®ä½ çš„å®é™…è·¯å¾„ä¿®æ”¹è¿™é‡Œ
BASE_DIR = "/root/autodl-fs/processed_data/CIC-IDS-2017-session-srcIP_srcPort_dstIP_dstPort_proto"
FLOW_CSV = os.path.join(BASE_DIR, "all_flow.csv")
SESSION_CSV = os.path.join(BASE_DIR, "all_split_session.csv")

# é‡‡æ ·ç‡ (æ¨¡æ‹Ÿè®­ç»ƒé…ç½®)
SAMPLE_RATIO = 0.1

# åˆ—åé…ç½®
TIME_COL = "conn.ts"  # æ—¶é—´æˆ³åˆ—å
LABEL_COL = "label"  # æ ‡ç­¾åˆ—å (æˆ– multiclass_label)
UID_COL = "uid"


# ===========================================

def print_header(title):
    print("\n" + "=" * 60)
    print(f" {title}")
    print("=" * 60)


def visualize_temporal_labels(df, title, num_buckets=50):
    """
    åœ¨æ—¶é—´è½´ä¸Šå¯è§†åŒ–æ ‡ç­¾åˆ†å¸ƒï¼Œç¡®è®¤æ˜¯å¦å‘ˆâ€œé˜¶æ¢¯çŠ¶â€å˜åŒ–
    """
    if df.empty:
        print(f"âš ï¸ {title} æ•°æ®ä¸ºç©º")
        return

    df = df.sort_values(TIME_COL)
    start_ts = df[TIME_COL].min()
    end_ts = df[TIME_COL].max()
    duration = end_ts - start_ts

    print(f"\nğŸ“Š {title} - æ ‡ç­¾æ—¶åºåˆ†å¸ƒ (æ—¶é—´è·¨åº¦: {duration / 3600:.2f} å°æ—¶)")
    print(f"   æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(start_ts)} -> {datetime.fromtimestamp(end_ts)}")
    print("-" * 60)
    print(f"{'æ—¶é—´è¿›åº¦':<15} | {'ä¸»è¦æ ‡ç­¾ (Top 3)':<40}")
    print("-" * 60)

    # åˆ†æ¡¶ç»Ÿè®¡
    df['bucket'] = pd.cut(df[TIME_COL], bins=num_buckets, labels=False)

    for i in range(num_buckets):
        bucket_data = df[df['bucket'] == i]
        if bucket_data.empty:
            continue

        # ç»Ÿè®¡è¯¥æ—¶é—´æ®µçš„æ ‡ç­¾
        counts = bucket_data[LABEL_COL].value_counts().head(3)
        label_str = ", ".join([f"{k}({v})" for k, v in counts.items()])

        # è®¡ç®—æ—¶é—´ç‚¹
        current_time = start_ts + (duration * (i / num_buckets))
        time_str = datetime.fromtimestamp(current_time).strftime('%m-%d %H:%M')

        print(f"{time_str:<15} | {label_str}")


def check_time_order(train_df, val_df, test_df):
    """ä¸¥æ ¼æ£€æŸ¥æ—¶é—´æœ‰åºæ€§"""
    print("\nğŸ” æ£€æŸ¥æ•°æ®é›†æ—¶é—´æœ‰åºæ€§ (Train -> Val -> Test)")

    t_max_train = train_df[TIME_COL].max()
    t_min_val = val_df[TIME_COL].min()
    t_max_val = val_df[TIME_COL].max()
    t_min_test = test_df[TIME_COL].min()

    print(f"  Train Max Time: {datetime.fromtimestamp(t_max_train)}")
    print(f"  Val   Min Time: {datetime.fromtimestamp(t_min_val)}")

    if t_max_train > t_min_val:
        print("  âŒ è­¦å‘Š: è®­ç»ƒé›†å’ŒéªŒè¯é›†æ—¶é—´é‡å ï¼(Flowæ¨¡å¼éšæœºæ‰“ä¹±ä¼šå¯¼è‡´æ­¤é—®é¢˜)")
    else:
        print("  âœ… è®­ç»ƒé›†å®Œå…¨åœ¨éªŒè¯é›†ä¹‹å‰")

    print(f"  Val   Max Time: {datetime.fromtimestamp(t_max_val)}")
    print(f"  Test  Min Time: {datetime.fromtimestamp(t_min_test)}")

    if t_max_val > t_min_test:
        print("  âŒ è­¦å‘Š: éªŒè¯é›†å’Œæµ‹è¯•é›†æ—¶é—´é‡å ï¼")
    else:
        print("  âœ… éªŒè¯é›†å®Œå…¨åœ¨æµ‹è¯•é›†ä¹‹å‰")


def load_flow_data_optimized():
    """åªè¯»å–å¿…è¦åˆ—ï¼ŒèŠ‚çœå†…å­˜"""
    print(f"æ­£åœ¨è¯»å– Flow æ•°æ®: {FLOW_CSV} ...")
    cols = [UID_COL, TIME_COL, LABEL_COL]
    df = pd.read_csv(FLOW_CSV, usecols=cols, low_memory=False)
    # ç¡®ä¿æŒ‰æ—¶é—´æ’åº (CIC-IDS-2017 åº”è¯¥æ˜¯å¤§è‡´æœ‰åºçš„ï¼Œè¿™é‡Œå¼ºåˆ¶æ’åºä»¥æ¨¡æ‹Ÿç†æƒ³æƒ…å†µ)
    df = df.sort_values(by=[TIME_COL])
    return df


# ==============================================================================
# æ¨¡æ‹Ÿ 1: Flow Mode (æœ‰åºé‡‡æ · + æœ‰åºåˆ‡åˆ†)
# ==============================================================================
def simulate_flow_mode(full_df):
    print_header("æ¨¡æ‹Ÿ MODE: FLOW (Ordered Sampling + No Shuffle)")

    # 1. æœ‰åºé‡‡æ · (Systematic Sampling)
    step = int(1 / SAMPLE_RATIO)
    sampled_df = full_df.iloc[::step].copy()
    print(f"é‡‡æ ·åæ•°æ®é‡: {len(sampled_df)} (Ratio: {SAMPLE_RATIO}, Step: {step})")

    # 2. æŒ‰é¡ºåºåˆ‡åˆ† (70% Train, 15% Val, 15% Test)
    n = len(sampled_df)
    train_end = int(n * 0.7)
    val_end = int(n * 0.85)

    train_df = sampled_df.iloc[:train_end]
    val_df = sampled_df.iloc[train_end:val_end]
    test_df = sampled_df.iloc[val_end:]

    # 3. éªŒè¯
    check_time_order(train_df, val_df, test_df)
    visualize_temporal_labels(train_df, "Flow-Train")
    visualize_temporal_labels(val_df, "Flow-Validate")
    visualize_temporal_labels(test_df, "Flow-Test")


# ==============================================================================
# æ¨¡æ‹Ÿ 2: Session Mode (è¯»å– split æ–‡ä»¶)
# ==============================================================================
def simulate_session_mode(full_df):
    print_header("æ¨¡æ‹Ÿ MODE: SESSION (åŸºäº all_split_session.csv)")

    if not os.path.exists(SESSION_CSV):
        print(f"âŒ æ‰¾ä¸åˆ° {SESSION_CSV}ï¼Œæ— æ³•éªŒè¯ Session æ¨¡å¼")
        return

    print(f"è¯»å– Session Split: {SESSION_CSV} ...")
    session_df = pd.read_csv(SESSION_CSV, usecols=['flow_uid_list', 'split'])

    # æ˜ å°„ UID -> Label/Time (ç”¨äºå¿«é€ŸæŸ¥æ‰¾)
    # full_df å·²ç»åªæœ‰å¿…è¦åˆ—äº†

    # æå– UID é›†åˆ
    print("è§£æ Session UID åˆ—è¡¨...")

    def get_uids(split_name):
        subset = session_df[session_df['split'] == split_name]
        uids = set()
        for x in subset['flow_uid_list']:
            try:
                # å…¼å®¹å­—ç¬¦ä¸²æˆ–åˆ—è¡¨æ ¼å¼
                l = ast.literal_eval(x) if isinstance(x, str) else x
                uids.update(l)
            except:
                pass
        return uids

    train_uids = get_uids('train')
    val_uids = get_uids('validate')
    test_uids = get_uids('test')

    print(f"Train UIDs: {len(train_uids)}, Val UIDs: {len(val_uids)}, Test UIDs: {len(test_uids)}")

    # è¿‡æ»¤ Flow
    print("æ­£åœ¨æ ¹æ® UID è¿‡æ»¤ Flow æ•°æ®...")
    # ä½¿ç”¨ isin è¿‡æ»¤
    train_df = full_df[full_df[UID_COL].isin(train_uids)]
    val_df = full_df[full_df[UID_COL].isin(val_uids)]
    test_df = full_df[full_df[UID_COL].isin(test_uids)]

    # é‡‡æ · (Sessionæ¨¡å¼é€šå¸¸ä¹Ÿé…åˆé‡‡æ ·ï¼Œè¿™é‡Œæ¨¡æ‹Ÿå¯¹ Flow çš„ç»“æœé‡‡æ ·ï¼Œæˆ–è€…ç›´æ¥çœ‹å…¨é‡)
    # å¦‚æœæ•°æ®é‡å¤ªå¤§ï¼Œè¿™é‡Œä»…åšå¯è§†åŒ–é‡‡æ ·
    if len(train_df) > 100000:
        train_df = train_df.iloc[::10]
        val_df = val_df.iloc[::10]
        test_df = test_df.iloc[::10]
        print("âš ï¸ ä¸ºåŠ é€Ÿå¯è§†åŒ–ï¼Œä»…å±•ç¤ºéƒ¨åˆ†æ•°æ®")

    # 3. éªŒè¯
    check_time_order(train_df, val_df, test_df)

    # é‡ç‚¹ï¼šå±•ç¤ºæ ‡ç­¾å˜åŒ–
    visualize_temporal_labels(train_df, "Session-Train")
    visualize_temporal_labels(val_df, "Session-Validate")
    visualize_temporal_labels(test_df, "Session-Test")


# ==============================================================================
# ä¸»ç¨‹åº
# ==============================================================================
if __name__ == "__main__":
    if not os.path.exists(FLOW_CSV):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {FLOW_CSV}")
        sys.exit(1)

    # 1. åŠ è½½å…¨é‡æ•°æ® (åªåŠ è½½ä¸€æ¬¡)
    df_all = load_flow_data_optimized()

    # 2. éªŒè¯ Flow æ¨¡å¼
    simulate_flow_mode(df_all)

    # 3. éªŒè¯ Session æ¨¡å¼
    simulate_session_mode(df_all)

    print("\nâœ… éªŒè¯å®Œæˆã€‚è¯·æ£€æŸ¥ä¸Šæ–¹æ—¥å¿—ä¸­çš„æ—¶é—´é‡å è­¦å‘Šå’Œæ ‡ç­¾åˆ†å¸ƒã€‚")
    print("   å¯¹äº CIC-IDS-2017ï¼Œä½ åº”è¯¥çœ‹åˆ°æ ‡ç­¾éšæ—¶é—´å‘ç”Ÿæ˜æ˜¾çš„ç±»åˆ«åˆ‡æ¢ (ä¾‹å¦‚ä» BENIGN å˜æˆ FTP-Patator)ã€‚")