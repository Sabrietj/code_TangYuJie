import hydra
from omegaconf import DictConfig, OmegaConf, ListConfig
import pytorch_lightning as pl
from pytorch_lightning.loggers import TensorBoardLogger
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
import os
import sys
import logging
import torch
from pytorch_lightning import seed_everything
from data.prepare_flow_file_pipeline import prepare_sampled_data_files

utils_path = os.path.join(os.path.dirname(__file__),  '..', '..', 'utils')
sys.path.insert(0, utils_path)
# è®¾ç½®æ—¥å¿—
from logging_config import setup_preset_logging
# ä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—é…ç½®
logger = setup_preset_logging(log_level=logging.INFO)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.flow_bert_multiview import FlowBertMultiview
from data.flow_bert_multiview_dataset import MultiviewFlowDataModule

def setup_environment(cfg: DictConfig):
    """æ ¹æ®ç¡¬ä»¶å¯ç”¨æ€§è‡ªåŠ¨è®¾ç½®è®­ç»ƒç¯å¢ƒ"""

    # ç§»é™¤ä¸å¿…è¦çš„TensorFlowç¯å¢ƒå˜é‡è®¾ç½®
    # os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ç§»é™¤è¿™è¡Œ
    # os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # ç§»é™¤è¿™è¡Œ

    force_single_gpu = cfg.get('force_single_gpu', False)

    # âœ… å¿…é¡»æœ€å…ˆåšï¼šå¼ºåˆ¶å• GPUï¼ˆåœ¨ä»»ä½• torch.cuda è°ƒç”¨ä¹‹å‰ï¼‰
    if force_single_gpu:
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"
        os.environ["PYTORCH_MPS_DISABLE"] = "1"  # ç¦ç”¨MPSä»¥é¿å…æ½œåœ¨å†²çª
        cfg.data.num_workers = 0  # å¼ºåˆ¶å•GPUæ—¶ï¼Œè®¾ç½®num_workersä¸º0ä»¥é¿å… DataLoader å¤šè¿›ç¨‹å¤æ‚æ€§
        logger.info("âœ… å¼ºåˆ¶ä½¿ç”¨å• GPU è®­ç»ƒï¼Œå·²è®¾ç½® CUDA_VISIBLE_DEVICES=0 å’Œ PYTORCH_MPS_DISABLE=1")

    # ä½¿ç”¨æ­£ç¡®çš„ç²¾åº¦è®¾ç½®API
    torch.set_float32_matmul_precision('high')  # æ¨èä½¿ç”¨ 'high'

    # è®¾ç½®ç¡®å®šæ€§æ“ä½œï¼ˆæœ‰åŠ©äºè°ƒè¯•ï¼‰
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

    # æ£€æµ‹CUDAå¯ç”¨æ€§
    if torch.cuda.is_available():
        cuda_count = torch.cuda.device_count()
        logger.info(f"æ£€æµ‹åˆ° {cuda_count} ä¸ªCUDAè®¾å¤‡å¯ç”¨")

        for i in range(torch.cuda.device_count()):
            logger.info(f"è®¾å¤‡ {i}: {torch.cuda.get_device_name(i)}")

        os.environ['PYTORCH_MPS_DISABLE'] = '1'  # ç¦ç”¨MPS

        accelerator = "gpu"
        if force_single_gpu:
            devices = 1
            strategy = "auto"
            logger.info("âœ… å¼ºåˆ¶ä½¿ç”¨å• GPU è®­ç»ƒ")
        else:
            devices = torch.cuda.device_count()
            # ç¡®ä¿ strategy æœ‰å€¼
            if devices > 1:
                strategy = "ddp_find_unused_parameters_true"  # å¯ç”¨æœªä½¿ç”¨å‚æ•°æ£€æµ‹
                logger.info("ä½¿ç”¨å¤šGPU DDPç­–ç•¥ï¼Œå¯ç”¨æœªä½¿ç”¨å‚æ•°æ£€æµ‹")
            else:
                strategy = "auto"
                logger.info("ä½¿ç”¨å•GPU è®­ç»ƒç­–ç•¥")

        logger.info("ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ")

    else:
        # æ£€æµ‹MPSå¯ç”¨æ€§
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            logger.info("æ£€æµ‹åˆ°MPSï¼ˆApple Siliconï¼‰å¯ç”¨")
            accelerator = "mps"
            devices = 1
            strategy = "auto"
            os.environ['PYTORCH_MPS_DISABLE'] = '0'  # å¯ç”¨MPS
            os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'  # å¯ç”¨MPSå›é€€
            logger.info("ä½¿ç”¨MPSè¿›è¡Œè®­ç»ƒ")
        else:
            logger.info("æœªæ£€æµ‹åˆ°GPU/MPSï¼Œä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
            accelerator = "cpu"
            devices = 1
            strategy = "auto"

    return accelerator, devices, strategy


def validate_config(cfg: DictConfig):
    """éªŒè¯é…ç½®å®Œæ•´æ€§"""
    required_fields = {
        'data.tabular_features': dict,
        'data.tabular_features.numeric_features.flow_features': list,
        'data.tabular_features.numeric_features.x509_features': list,
        'data.tabular_features.numeric_features.dns_features': list,
        'data.is_malicious_column': str,
        'data.multiclass_label_column': str,
        'data.text_features.enabled': bool,
        'data.domain_name_embedding_features.enabled': bool,
        'data.domain_name_embedding_features.column_list': list,
        'data.sequence_features.enabled': bool,
        'model.sequence.embedding_dim': int,
        'model.bert.model_name': str,
        'model.multiview.fusion.method': str,
    }

    # å¯é€‰å­—æ®µ - ä¿®æ­£æœŸæœ›ç±»å‹
    optional_fields = {
        'data.sequence_features': dict,  # æ­£ç¡®ï¼šæœŸæœ›å­—å…¸ç±»å‹
        'data.text_features': dict,      # æ­£ç¡®ï¼šæœŸæœ›å­—å…¸ç±»å‹
        'data.domain_name_embedding_features': dict  # æ­£ç¡®ï¼šæœŸæœ›åˆ—è¡¨ç±»å‹
    }

    # éªŒè¯å¿…éœ€å­—æ®µ
    for field, expected_type in required_fields.items():
        value = OmegaConf.select(cfg, field)
        if value is None:
            raise ValueError(f"ç¼ºå°‘å¿…è¦é…ç½®: {field}")

        # å¤„ç†ä¸åŒç±»å‹çš„éªŒè¯
        if expected_type == list:
            if not isinstance(value, (list, ListConfig)):
                raise ValueError(f"é…ç½® {field} ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›åˆ—è¡¨ç±»å‹ï¼Œå®é™… {type(value)}")
            if len(value) == 0:
                raise ValueError(f"é…ç½® {field} ä¸èƒ½ä¸ºç©ºåˆ—è¡¨")

        elif expected_type == dict:
            if not isinstance(value, (dict, DictConfig)):
                raise ValueError(f"é…ç½® {field} ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›å­—å…¸ç±»å‹ï¼Œå®é™… {type(value)}")
            if len(value) == 0:
                raise ValueError(f"é…ç½® {field} ä¸èƒ½ä¸ºç©ºå­—å…¸")

        elif expected_type == str:
            if not isinstance(value, str):
                raise ValueError(f"é…ç½® {field} ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›å­—ç¬¦ä¸²ç±»å‹ï¼Œå®é™… {type(value)}")
            if not value.strip():
                raise ValueError(f"é…ç½® {field} ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²")

        elif expected_type == int:
            if not isinstance(value, int):
                raise ValueError(f"é…ç½® {field} ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›æ•´æ•°ç±»å‹ï¼Œå®é™… {type(value)}")
            if value <= 0:
                raise ValueError(f"é…ç½® {field} å¿…é¡»æ˜¯æ­£æ•´æ•°")

    # éªŒè¯å¯é€‰å­—æ®µ - ä¿®æ­£éªŒè¯é€»è¾‘
    for field, expected_type in optional_fields.items():
        value = OmegaConf.select(cfg, field)
        if value is not None:  # åªæœ‰å½“å­—æ®µå­˜åœ¨æ—¶æ‰éªŒè¯
            # å¤„ç†ä¸åŒç±»å‹çš„éªŒè¯
            if expected_type == list:
                if not isinstance(value, (list, ListConfig)):
                    raise ValueError(f"é…ç½® {field} ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›åˆ—è¡¨ç±»å‹ï¼Œå®é™… {type(value)}")
                # å¯é€‰å­—æ®µå…è®¸ç©ºåˆ—è¡¨

            elif expected_type == dict:
                if not isinstance(value, (dict, DictConfig)):
                    raise ValueError(f"é…ç½® {field} ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›å­—å…¸ç±»å‹ï¼Œå®é™… {type(value)}")
                # å¯é€‰å­—æ®µå…è®¸ç©ºå­—å…¸

            elif expected_type == str:
                if not isinstance(value, str):
                    raise ValueError(f"é…ç½® {field} ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›å­—ç¬¦ä¸²ç±»å‹ï¼Œå®é™… {type(value)}")
                if not value.strip():
                    raise ValueError(f"é…ç½® {field} ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²")

            elif expected_type == int:
                if not isinstance(value, int):
                    raise ValueError(f"é…ç½® {field} ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›æ•´æ•°ç±»å‹ï¼Œå®é™… {type(value)}")
                if value <= 0:
                    raise ValueError(f"é…ç½® {field} å¿…é¡»æ˜¯æ­£æ•´æ•°")

    if not hasattr(cfg.optimizer, 'default_total_steps'):
        logger.warning("optimizer.default_total_steps æœªé…ç½®ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼10000")
        cfg.optimizer.default_total_steps = 10000

    # éªŒè¯èåˆæ–¹æ³•é…ç½®
    fusion_method = cfg.model.multiview.fusion.method

    if fusion_method == "cross_attention":
        if not hasattr(cfg.model.multiview.fusion, 'cross_attention_heads'):
            raise ValueError("äº¤å‰æ³¨æ„åŠ›èåˆéœ€è¦é…ç½® cross_attention_heads")
        if not hasattr(cfg.model.multiview.fusion, 'cross_attention_dropout'):
            raise ValueError("äº¤å‰æ³¨æ„åŠ›èåˆéœ€è¦é…ç½® cross_attention_dropout")

    elif fusion_method == "weighted_sum":
        if not hasattr(cfg.model.multiview.fusion, 'weighted_sum'):
            raise ValueError("åŠ æƒæ±‚å’Œèåˆéœ€è¦é…ç½® weighted_sum")

    elif fusion_method == "concat":
        # ğŸ”´ æ‹¼æ¥æ–¹æ³•ä¸å†éœ€è¦é¢å¤–é…ç½®éªŒè¯
        pass  # æ‹¼æ¥æ–¹æ³•ä¸éœ€è¦é¢å¤–é…ç½®

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„èåˆæ–¹æ³•: {fusion_method}")

    # é¢å¤–çš„é…ç½®é€»è¾‘éªŒè¯
    logger.info("é…ç½®éªŒè¯é€šè¿‡")


def resolve_dataset_paths(cfg):
    dataset_cfg = cfg.datasets

    # å†™å›ç»Ÿä¸€ä½¿ç”¨çš„å­—æ®µ
    assert "flow_data_path" in dataset_cfg
    cfg.data.flow_data_path = dataset_cfg.flow_data_path

    assert "session_split_path" in dataset_cfg
    cfg.data.session_split.session_split_path = dataset_cfg.session_split_path

    logger.info(
        f"ğŸ“¦ ä½¿ç”¨æ•°æ®é›†: {cfg.data.dataset}\n"
        f"  flow_data_path = {cfg.data.flow_data_path}\n"
        f"  session_split_path = {cfg.data.session_split.session_split_path}"
    )

@hydra.main(config_path="./config", config_name="flow_bert_multiview_config", version_base=None)
def main(cfg: DictConfig):
    os.environ['HYDRA_FULL_ERROR'] = '1'

    logger = setup_preset_logging(log_level=logging.INFO)

    # logger.info("å¤šè§†å›¾BERT-Multiviewè®­ç»ƒé…ç½®:")
    # logger.info(f"\n{OmegaConf.to_yaml(cfg)}")

    # æ‰“å°é…ç½®ä»¥è°ƒè¯•
    # logger.info("BERTæ¨¡å‹åç§°:", cfg.model.bert.model_name)

    try:
        seed_everything(cfg.data.random_state, workers=True)
        os.chdir(hydra.utils.get_original_cwd())

        accelerator, devices, strategy = setup_environment(cfg)

        # æ·»åŠ é…ç½®éªŒè¯
        validate_config(cfg)

        # é€‰æ‹©æ•°æ®é›†é…ç½®
        resolve_dataset_paths(cfg)

        # sample flow data if needed
        prepare_sampled_data_files(cfg)
        logger.info(f"âœ… æœ€ç»ˆç”¨äºè®­ç»ƒçš„ flow_data_path = {cfg.data.flow_data_path}")

        datamodule = MultiviewFlowDataModule(cfg)
        datamodule.setup("fit")   # â­ å…ˆæ„å»ºæ•°æ®

        model = FlowBertMultiview(cfg, dataset=datamodule.train_dataset)

        # âœ… ç«‹å³æ£€æŸ¥æ¦‚å¿µæ¼‚ç§»æ£€æµ‹å™¨çŠ¶æ€
        if hasattr(model, 'drift_detector') and model.drift_detector is not None:
            logger.info("âœ… BNDMæ¦‚å¿µæ¼‚ç§»æ£€æµ‹å™¨å·²åˆ›å»º")

            # æ‰“å°è¯¦ç»†é…ç½®
            stats = model.drift_detector.get_statistics()
            logger.info("ğŸ“Š æ¦‚å¿µæ¼‚ç§»æ£€æµ‹å™¨åˆå§‹é…ç½®:")
            logger.info(f"  ç‰¹å¾ç»´åº¦: {stats['feature_dim']}")
            logger.info(f"  çª—å£å¤§å°: {stats['window_size']}")
            logger.info(f"  é˜ˆå€¼Ï„: {stats['detection_threshold']:.6f}")
            logger.info(f"  min_samples: {stats['min_samples']}")
            logger.info(f"  æ¼‚ç§»ç±»å‹: {stats['drift_type']}")
            logger.info(f"  å½“å‰çŠ¶æ€: {stats['status']}")
            logger.info(f"  æœŸæœ›è¡Œä¸º: å…ˆæ”¶é›†{stats['min_samples']}ä¸ªæ ·æœ¬ï¼Œç„¶åå¼€å§‹æ£€æµ‹")

        logger_tb = TensorBoardLogger(
            save_dir=cfg.logging.save_dir,
            name=cfg.logging.name,
            version=cfg.logging.get('version')
        )

        checkpoint_callback = ModelCheckpoint(
            monitor=cfg.training.model_checkpoint.monitor,
            mode=cfg.training.model_checkpoint.mode,
            save_top_k=cfg.training.model_checkpoint.save_top_k,
            filename=cfg.training.model_checkpoint.filename,
            auto_insert_metric_name=False
        )

        early_stopping = EarlyStopping(
            monitor=cfg.training.early_stopping.monitor,
            patience=cfg.training.early_stopping.patience,
            mode=cfg.training.early_stopping.mode,
            min_delta=cfg.training.early_stopping.get('min_delta', 0.001)
        )

        # åˆ›å»ºæ¦‚å¿µæ¼‚ç§»ç›‘æ§å›è°ƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
        drift_callbacks = []
        if hasattr(cfg.training, 'drift_monitor') and cfg.training.drift_monitor.enabled:
            try:
                from pytorch_lightning.callbacks import Callback

                class DriftMonitorCallback(Callback):
                    """æ¦‚å¿µæ¼‚ç§»ç›‘æ§å›è°ƒ"""

                    def __init__(self, check_interval=50):
                        super().__init__()
                        self.check_interval = check_interval
                        self.batch_count = 0

                    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
                        self.batch_count += 1

                        # å®šæœŸæ£€æŸ¥æ¦‚å¿µæ¼‚ç§»
                        # å®šæœŸæ£€æŸ¥æ¦‚å¿µæ¼‚ç§»
                        if self.batch_count % self.check_interval == 0:
                            if hasattr(pl_module, 'drift_detector') and pl_module.drift_detector is not None:
                                is_drift, B, info = pl_module.drift_detector.detect_drift()

                                if is_drift:
                                    # è®°å½•åˆ°TensorBoard
                                    # æ³¨æ„ï¼šLog Bayes Factor å¯èƒ½ä¸ºè´Ÿæ•°ï¼ŒB å¯èƒ½æ¥è¿‘ 0
                                    trainer.logger.log_metrics({
                                        'drift/active_detection': 1.0,
                                        'drift/bayes_factor': B,
                                        'drift/log_bayes_factor': info.get('log_bayes_factor', 0)
                                    }, step=trainer.global_step)
                                else:
                                    # ä¹Ÿå¯ä»¥è®°å½•æ­£å¸¸çŠ¶æ€ä¸‹çš„ B å€¼ä»¥ä¾¿è§‚å¯Ÿ
                                    trainer.logger.log_metrics({
                                        'drift/active_detection': 0.0,
                                        'drift/bayes_factor': B,
                                        'drift/log_bayes_factor': info.get('log_bayes_factor', 0)
                                    }, step=trainer.global_step)

                drift_callback = DriftMonitorCallback(
                    check_interval=cfg.training.drift_monitor.get('check_interval', 50)
                )
                drift_callbacks.append(drift_callback)
                logger.info("âœ… æ¦‚å¿µæ¼‚ç§»ç›‘æ§å›è°ƒå·²å¯ç”¨")

            except Exception as e:
                logger.warning(f"æ¦‚å¿µæ¼‚ç§»å›è°ƒåˆ›å»ºå¤±è´¥: {e}")

        # ğŸ”§ ç¡®ä¿detect_anomalyé…ç½®ç”Ÿæ•ˆ
        detect_anomaly = cfg.training.get('detect_anomaly', False)
        logger.info(f"è®¾ç½®æ¨¡å‹è®­ç»ƒçš„å¼‚å¸¸æ£€æµ‹å¼€å…³: detect_anomaly = {detect_anomaly}")

        # æ„å»ºå›è°ƒåˆ—è¡¨
        callbacks = [checkpoint_callback, early_stopping, LearningRateMonitor(logging_interval='step')]
        callbacks.extend(drift_callbacks)

        trainer = pl.Trainer(
            max_epochs=cfg.training.max_epochs,
            accelerator=accelerator,
            devices=devices,
            precision=cfg.training.precision,
            gradient_clip_val=cfg.training.gradient_clip_val,
            gradient_clip_algorithm=cfg.training.get('gradient_clip_algorithm', 'norm'),
            accumulate_grad_batches=cfg.training.accumulate_grad_batches,
            log_every_n_steps=cfg.training.log_every_n_steps,
            logger=logger_tb,
            callbacks=[checkpoint_callback, early_stopping, LearningRateMonitor(logging_interval='step')],
            strategy=strategy,
            enable_progress_bar=True,
            detect_anomaly=detect_anomaly,
        )

        logger.info("å¼€å§‹è®­ç»ƒå¤šè§†å›¾BERTæ¨¡å‹...")
        trainer.fit(model, datamodule=datamodule)
        logger.info("è®­ç»ƒå®Œæˆï¼")

        logger.info("æ­£åœ¨å¯¼å‡ºæœ€ä½³æ¨¡å‹åˆ° src/checkpoints ç›®å½•...")

        # 1. æ„é€ ç›®æ ‡è·¯å¾„ï¼šsrc/checkpoints/best_model.ckpt
        # orig_cwd æ˜¯é¡¹ç›®æ ¹ç›®å½•
        target_dir = os.path.join(orig_cwd, "src", "checkpoints")
        os.makedirs(target_dir, exist_ok=True)
        target_path = os.path.join(target_dir, "best_model.ckpt")

        # 2. è·å– Lightning ä¿å­˜çš„ä¸´æ—¶è·¯å¾„
        best_model_path = checkpoint_callback.best_model_path

        # 3. æ‰§è¡Œå¤åˆ¶
        if best_model_path and os.path.exists(best_model_path):
            shutil.copy(best_model_path, target_path)
            logger.info(f"âœ… [SUCCESS] æœ€ä½³æ¨¡å‹å·²å¯¼å‡ºåˆ°: {target_path}")
            # æ›´æ–° best_model_path å˜é‡ï¼Œä¾›åç»­æµ‹è¯•ä½¿ç”¨
            best_model_path = target_path
        else:
            logger.error(f"âŒ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶: {best_model_path}ï¼Œæ— æ³•å¯¼å‡ºï¼")
        # ==========================================================

        # æµ‹è¯•æ¨¡å‹ï¼ˆåŠ è½½åˆšæ‰å¯¼å‡ºçš„æœ€ä½³æ¨¡å‹ï¼‰
        logger.info("å¼€å§‹æµ‹è¯•ï¼ˆåŠ è½½æœ€ä½³æ¨¡å‹ï¼‰...")
        logger.info(f"åŠ è½½è·¯å¾„: {best_model_path}")

        # ä½¿ç”¨å¯¼å‡ºçš„è·¯å¾„é‡æ–°åŠ è½½æ¨¡å‹
        best_model = FlowBertMultiview.load_from_checkpoint(
            best_model_path,
            cfg=cfg,
            dataset=datamodule.train_dataset
        )

        trainer_test = pl.Trainer(
            accelerator="gpu" if torch.cuda.is_available() else "cpu",
            devices=1,
            logger=False,
            enable_checkpointing=False,
        )
        trainer_test.test(best_model, datamodule=datamodule)

        if hasattr(best_model, 'drift_detector') and best_model.drift_detector is not None:
            best_model.on_test_end()

    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}", exc_info=True)
        raise

if __name__ == "__main__":
    main() # pyright: ignore[reportCallIssue]
