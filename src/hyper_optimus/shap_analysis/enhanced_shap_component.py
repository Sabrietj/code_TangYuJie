"""
å¢å¼ºç‰ˆSHAPç»„ä»¶ - é›†æˆäº”å¤§ç‰¹å¾ç±»åˆ«åˆ†ææ¶æ„
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import os
import logging
from typing import Dict, List, Any, Optional

from .five_tier_analyzer import FiveTierSHAPAnalyzer
from .multi_model_adapter import MultiModelSHAPAdapter

logger = logging.getLogger(__name__)

class EnhancedShapAnalyzer:
    """
    å¢å¼ºç‰ˆSHAPåˆ†æå™¨ï¼Œé›†æˆäº”å¤§ç‰¹å¾ç±»åˆ«åˆ†ææ¶æ„
    è§£å†³åŸæœ‰çš„ç»´åº¦ä¸åŒ¹é…ã€ç‰¹å¾åˆ†ç±»æ··ä¹±ã€è·¨æ¨¡å‹å…¼å®¹æ€§é—®é¢˜
    """
    
    def __init__(self, model, enable_five_tier_analysis: bool = True):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆSHAPåˆ†æå™¨
        
        Args:
            model: è¦åˆ†æçš„æ¨¡å‹å®ä¾‹
            enable_five_tier_analysis: æ˜¯å¦å¯ç”¨äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†æ
        """
        self.model = model
        self.cfg = model.cfg
        self.enable_five_tier_analysis = enable_five_tier_analysis
        
        # ç¼“å†²åŒºè®¾ç½®
        self.buffer = []
        self.sample_limit = 100  # é™åˆ¶åˆ†ææ ·æœ¬æ•°ï¼Œé˜²æ­¢OOM
        self.collected_count = 0
        self.enabled = True
        
        # åˆå§‹åŒ–äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†æå™¨
        if self.enable_five_tier_analysis:
            adapter = MultiModelSHAPAdapter()
            model_type = adapter.auto_detect_model_type(model)
            
            self.five_tier_analyzer = FiveTierSHAPAnalyzer(
                model=model, 
                model_type=model_type,
                config=self._get_five_tier_config()
            )
            logger.info(f"å¢å¼ºç‰ˆSHAPåˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹ç±»å‹: {model_type}")
        else:
            self.five_tier_analyzer = None
            logger.info("å¢å¼ºç‰ˆSHAPåˆ†æå™¨ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼")
    
    def _get_five_tier_config(self) -> Dict[str, Any]:
        """è·å–äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†æé…ç½®"""
        return {
            'shap': {
                'enable_level1_analysis': True,   # å¯ç”¨å¤§ç±»åˆ«åˆ†æï¼ˆé¥¼å›¾ï¼‰
                'enable_level2_analysis': True,   # å¯ç”¨å…·ä½“ç‰¹å¾åˆ†æï¼ˆæŸ±çŠ¶å›¾ï¼‰
                'focus_numeric_features': True,   # é‡ç‚¹åˆ†ææ•°å€¼ç‰¹å¾
                'dynamic_dimension_calculation': True,  # åŠ¨æ€è®¡ç®—ç‰¹å¾ç»´åº¦
                'enable_data_validation': True,
                'save_plots': True,
                'background_samples': 50,
                'eval_samples': 20
            },
            'logging': {
                'save_dir': './shap_results',
                'name': 'enhanced_five_tier_analysis',
                'version': 'default'
            }
        }
    
    def reset(self):
        """æ¯ä¸ªepochå¼€å§‹æ—¶é‡ç½®ç¼“å†²åŒº"""
        self.buffer = []
        self.collected_count = 0
    
    def collect_batch(self, batch: Dict[str, Any]):
        """æ”¶é›†æµ‹è¯•é˜¶æ®µçš„Batchæ•°æ® (CPUç¼“å­˜)"""
        if not self.enabled or self.collected_count >= self.sample_limit:
            return
        
        # ç§»åŠ¨åˆ°CPUå¹¶åˆ†ç¦»è®¡ç®—å›¾ï¼Œåªä¿ç•™æ•°æ®
        batch_cpu = {}
        batch_size = 0
        
        with torch.no_grad():
            for k, v in batch.items():
                if isinstance(v, torch.Tensor):
                    batch_cpu[k] = v.detach().cpu()
                    if batch_size == 0: 
                        batch_size = v.shape[0]
                elif isinstance(v, list):
                    batch_cpu[k] = v
                else:
                    batch_cpu[k] = v  # å…ƒæ•°æ®ç­‰
        
        self.buffer.append(batch_cpu)
        self.collected_count += batch_size
    
    def finalize(self):
        """æµ‹è¯•ç»“æŸæ—¶æ‰§è¡ŒSHAPåˆ†æ"""
        # åªåœ¨ä¸»è¿›ç¨‹æ‰§è¡Œ
        if hasattr(self.model, 'trainer') and not self.model.trainer.is_global_zero:
            return
        
        if not self.buffer:
            logger.warning("[EnhancedShapAnalyzer] æœªæ”¶é›†åˆ°æ ·æœ¬ï¼Œè·³è¿‡åˆ†æ")
            return
        
        logger.info("=" * 80)
        logger.info(f"ğŸ” [EnhancedShapAnalyzer] å¼€å§‹æ‰§è¡Œå¢å¼ºç‰ˆç‰¹å¾å½’å› åˆ†æ (æ ·æœ¬æ•°: {self.collected_count})...")
        
        try:
            if self.enable_five_tier_analysis and self.five_tier_analyzer is not None:
                self._run_five_tier_analysis()
            else:
                self._run_legacy_analysis()
        except Exception as e:
            logger.error(f"âŒ [EnhancedShapAnalyzer] åˆ†æå¤±è´¥: {e}", exc_info=True)
        
        logger.info("=" * 80)
    
    def _run_five_tier_analysis(self):
        """æ‰§è¡Œäº”å¤§ç‰¹å¾ç±»åˆ«åˆ†æ"""
        logger.info("ğŸ¯ å¯ç”¨äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†ææ¶æ„...")
        
        # ======================================================================
        # ğŸ”´ ç»ˆæä¿®å¤: é€€å‡º Inference Mode + å¼€å¯ Grad
        # PyTorch Lightning çš„ test é˜¶æ®µé»˜è®¤å¤„äº inference_mode (æ¯” no_grad æ›´å¼º)
        # å¿…é¡»æ˜¾å¼é€€å‡º inference_mode æ‰èƒ½æ„å»ºè®¡ç®—å›¾
        # ======================================================================
        with torch.inference_mode(False):  # 1. é€€å‡ºæ¨ç†æ¨¡å¼
            with torch.enable_grad():      # 2. å¼€å¯æ¢¯åº¦è®¡ç®—
                
                # 3. å†æ¬¡ç¡®ä¿æ¨¡å‹å‚æ•°å…è®¸æ±‚å¯¼ (åŒé‡ä¿é™©)
                for param in self.model.parameters():
                    param.requires_grad = True
                
                try:
                    # 1. åˆå¹¶ç¼“å†²åŒºæ•°æ®
                    combined_batch = self._merge_buffer()
                    
                    # éªŒè¯è®¡ç®—å›¾çŠ¶æ€
                    logger.info(f"[EnhancedShapAnalyzer] è®¡ç®—å›¾çŠ¶æ€æ£€æŸ¥:")
                    logger.info(f"  is_grad_enabled: {torch.is_grad_enabled()}")
                    logger.info(f"  is_inference_mode: {torch.is_inference_mode_enabled()}")
                    
                    # 2. æ‰§è¡Œäº”å¤§ç‰¹å¾ç±»åˆ«åˆ†æ
                    results = self.five_tier_analyzer.analyze(combined_batch)
                    
                    # 3. ä¿å­˜ç»“æœ
                    output_path = self.five_tier_analyzer.save_results(
                        results, 
                        experiment_name='enhanced_five_tier_analysis'
                    )
                    
                    # 4. è¾“å‡ºæ‘˜è¦
                    self._print_five_tier_summary(results)
                    
                    logger.info(f"âœ… [EnhancedShapAnalyzer] äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜è‡³: {output_path}")
                    
                except Exception as e:
                    logger.error(f"äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                    raise
    
    def _run_legacy_analysis(self):
        """æ‰§è¡Œä¼ ç»ŸSHAPåˆ†æï¼ˆå…¼å®¹æ€§ï¼‰"""
        logger.info("ğŸ”„ ä½¿ç”¨ä¼ ç»ŸSHAPåˆ†ææ¨¡å¼...")
        
        # è¿™é‡Œå¯ä»¥é›†æˆåŸæ¥çš„ShapComponenté€»è¾‘
        # ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸæœ‰åˆ†ææ–¹å¼
        from .shap_component import ShapAnalyzer
        
        # åˆ›å»ºä¼ ç»Ÿåˆ†æå™¨å®ä¾‹
        legacy_analyzer = ShapAnalyzer(self.model)
        legacy_analyzer.buffer = self.buffer
        legacy_analyzer.collected_count = self.collected_count
        
        # æ‰§è¡Œä¼ ç»Ÿåˆ†æ
        legacy_analyzer.finalize()
    
    def _merge_buffer(self) -> Dict[str, Any]:
        """åˆå¹¶ç¼“å†²åŒºæ•°æ®"""
        if not self.buffer:
            return {}
        
        combined = {}
        keys = self.buffer[0].keys()
        
        for k in keys:
            val = self.buffer[0][k]
            if isinstance(val, torch.Tensor):
                combined[k] = torch.cat([b[k] for b in self.buffer], dim=0)
            elif isinstance(val, list):
                combined[k] = [item for b in self.buffer for item in b[k]]
        
        return combined
    
    def _print_five_tier_summary(self, results: Dict[str, Any]):
        """æ‰“å°äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†ææ‘˜è¦"""
        summary = results['analysis_summary']
        five_tier = results['five_tier_analysis']
        
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š äº”å¤§ç‰¹å¾ç±»åˆ«SHAPåˆ†ææŠ¥å‘Š")
        logger.info("=" * 60)
        
        logger.info(f"æ¨¡å‹ç±»å‹: {summary['model_type']}")
        logger.info(f"ç»´åº¦å…¼å®¹æ€§: {summary['dimension_compatibility']}")
        logger.info(f"åˆ†ææ—¶é—´: {summary['analysis_timestamp']}")
        logger.info(f"SHAPæ–¹æ³•: {summary['shap_method']}")
        
        logger.info("\nğŸ¯ Level 1: å¤§ç±»åˆ«é‡è¦æ€§åˆ†å¸ƒ")
        level1_importance = five_tier['level1_category_importance']
        for category, importance in sorted(level1_importance.items(), key=lambda x: x[1], reverse=True):
            if importance > 0.1:  # åªæ˜¾ç¤ºå¤§äº0.1%çš„ç±»åˆ«
                logger.info(f"  {category.replace('_', ' ').title()}: {importance:.2f}%")
        
        logger.info("\nğŸ“ˆ Level 2: Top 10 æ•°å€¼ç‰¹å¾")
        level2_importance = five_tier['level2_numeric_importance']
        for i, (feature, importance) in enumerate(list(level2_importance.items())[:10], 1):
            logger.info(f"  {i:2d}. {feature}: {importance:.4f}")
        
        logger.info("\nğŸ”§ ç‰¹å¾åˆ†ç±»ç»Ÿè®¡")
        feature_classification = five_tier['feature_classification']
        for category, features in feature_classification.items():
            logger.info(f"  {category}: {len(features)} ä¸ªç‰¹å¾")
        
        logger.info("=" * 60)
    
    def get_analysis_capabilities(self) -> Dict[str, Any]:
        """è·å–åˆ†æèƒ½åŠ›ä¿¡æ¯"""
        capabilities = {
            'supports_five_tier_analysis': self.enable_five_tier_analysis,
            'model_type': None,
            'feature_classification': None,
            'dimension_validation': None,
            'supported_visualizations': []
        }
        
        if self.enable_five_tier_analysis and self.five_tier_analyzer is not None:
            adapter = MultiModelSHAPAdapter()
            capabilities['model_type'] = adapter.auto_detect_model_type(self.model)
            
            # è·å–ç‰¹å¾åˆ†ç±»èƒ½åŠ›
            if hasattr(self.five_tier_analyzer.feature_classifier, 'get_feature_hierarchy_info'):
                hierarchy_info = self.five_tier_analyzer.feature_classifier.get_feature_hierarchy_info()
                capabilities['feature_classification'] = hierarchy_info
            
            # è·å–ç»´åº¦éªŒè¯èƒ½åŠ›
            if hasattr(self.five_tier_analyzer.dimension_extractor, 'calculate_all_dimensions'):
                dimensions = self.five_tier_analyzer.dimension_extractor.calculate_all_dimensions()
                capabilities['dimension_validation'] = {
                    'supported_dimensions': list(dimensions.keys()),
                    'total_input_dims': dimensions.get('total_input_dims', 0)
                }
            
            # è·å–å¯è§†åŒ–æ”¯æŒ
            if self.five_tier_analyzer.config['shap']['enable_level1_analysis']:
                capabilities['supported_visualizations'].append('pie_chart')
            if self.five_tier_analyzer.config['shap']['enable_level2_analysis']:
                capabilities['supported_visualizations'].append('bar_chart')
        
        return capabilities
    
    def enable_five_tier_mode(self, enable: bool = True):
        """åŠ¨æ€å¯ç”¨/ç¦ç”¨äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†ææ¨¡å¼"""
        self.enable_five_tier_analysis = enable
        
        if enable and self.five_tier_analyzer is None:
            adapter = MultiModelSHAPAdapter()
            model_type = adapter.auto_detect_model_type(self.model)
            
            self.five_tier_analyzer = FiveTierSHAPAnalyzer(
                model=self.model, 
                model_type=model_type,
                config=self._get_five_tier_config()
            )
            logger.info(f"äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†ææ¨¡å¼å·²å¯ç”¨ï¼Œæ¨¡å‹ç±»å‹: {model_type}")
        elif not enable:
            logger.info("äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†ææ¨¡å¼å·²ç¦ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿåˆ†ææ¨¡å¼")
    
    def update_config(self, new_config: Dict[str, Any]):
        """æ›´æ–°åˆ†æé…ç½®"""
        if self.five_tier_analyzer is not None:
            # åˆå¹¶é…ç½®
            current_config = self.five_tier_analyzer.config
            for key, value in new_config.items():
                if key in current_config:
                    if isinstance(current_config[key], dict) and isinstance(value, dict):
                        current_config[key].update(value)
                    else:
                        current_config[key] = value
                else:
                    current_config[key] = value
            
            logger.info("å¢å¼ºç‰ˆSHAPåˆ†æå™¨é…ç½®å·²æ›´æ–°")
    
    def get_recent_results(self) -> Optional[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„åˆ†æç»“æœ"""
        return getattr(self, 'analysis_results', None)