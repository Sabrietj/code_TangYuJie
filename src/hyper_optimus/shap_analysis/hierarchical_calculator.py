"""
åˆ†å±‚SHAPè®¡ç®—å™¨ - Level 1å¤§ç±»åˆ«ï¼ŒLevel 2å…·ä½“ç‰¹å¾
"""

import torch
import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Any, Tuple
try:
    import shap
except ImportError:
    shap = None
from .enhanced_wrapper import EnhancedShapFusionWrapper
from .dimension_extractor import ConfigDimensionExtractor

logger = logging.getLogger(__name__)

class HierarchicalSHAPCalculator:
    """åˆ†å±‚SHAPè®¡ç®—å™¨ï¼šLevel 1å¤§ç±»åˆ«ï¼ŒLevel 2å…·ä½“ç‰¹å¾"""
    
    def __init__(self, model, feature_classification: Dict[str, List[str]]):
        self.model = model
        self.feature_classification = feature_classification
        self.cfg = model.cfg
        
        # åˆå§‹åŒ–å¢å¼ºåŒ…è£…å™¨
        self.wrapper = EnhancedShapFusionWrapper(model)
        self.dimension_extractor = ConfigDimensionExtractor(self.cfg)
        self.feature_dims = self.dimension_extractor.calculate_all_dimensions()
        
        logger.info(f"HierarchicalSHAPCalculatoråˆå§‹åŒ–å®Œæˆï¼Œç‰¹å¾ç»´åº¦: {self.feature_dims}")
    
    def calculate_level1_importance(self, explainer: Any, 
                                background_inputs: List[torch.Tensor], 
                                eval_inputs: List[torch.Tensor]) -> Dict[str, float]:
        """
        Level 1: è®¡ç®—5å¤§ç‰¹å¾ç±»åˆ«çš„SHAPé‡è¦æ€§ï¼ˆé¥¼å›¾ç›®æ ‡ï¼‰
        
        Returns:
            Dict[str, float]: 5å¤§ç‰¹å¾ç±»åˆ«çš„SHAPé‡è¦æ€§ç™¾åˆ†æ¯”
        """
        try:
            # è®¡ç®—SHAPå€¼
            shap_values = explainer.shap_values(eval_inputs, check_additivity=False)
            
            # æŒ‰äº”å¤§ç‰¹å¾ç±»åˆ«åˆ†ç»„è®¡ç®—é‡è¦æ€§
            category_importance = {
                'numeric_features': 0.0,
                'categorical_features': 0.0, 
                'sequence_features': 0.0,
                'text_features': 0.0,
                'domain_embedding_features': 0.0
            }
            
            # SHAPå€¼æ ¼å¼: [numeric, domain, categorical, sequence, text]
            # å¯¹åº” enhanced wrapper forward çš„5ä¸ªè¾“å…¥é¡ºåº
            
            # 1. æ•°å€¼ç‰¹å¾é‡è¦æ€§ (ç¬¬ä¸€ä¸ªè¾“å…¥)
            if len(shap_values) > 0 and shap_values[0] is not None:
                numeric_shap = shap_values[0]
                if torch.is_tensor(numeric_shap):
                    numeric_shap = numeric_shap.cpu().numpy()
                # å¯¹æ‰€æœ‰æ•°å€¼ç‰¹å¾ç»´åº¦æ±‚å’Œï¼Œå†å¯¹æ‰€æœ‰æ ·æœ¬æ±‚å¹³å‡
                category_importance['numeric_features'] = float(np.abs(numeric_shap).sum())
            
            # 2. åŸŸååµŒå…¥ç‰¹å¾é‡è¦æ€§ (ç¬¬äºŒä¸ªè¾“å…¥)
            if len(shap_values) > 1 and shap_values[1] is not None and self.model.domain_embedding_enabled:
                domain_shap = shap_values[1]
                if torch.is_tensor(domain_shap):
                    domain_shap = domain_shap.cpu().numpy()
                category_importance['domain_embedding_features'] = float(np.abs(domain_shap).sum())
            
            # 3. ç±»åˆ«ç‰¹å¾é‡è¦æ€§ (ç¬¬ä¸‰ä¸ªè¾“å…¥)
            if len(shap_values) > 2 and shap_values[2] is not None:
                categorical_columns_effective = getattr(self.model, 'categorical_columns_effective', [])
                if len(categorical_columns_effective) > 0:
                    categorical_shap = shap_values[2]
                    if torch.is_tensor(categorical_shap):
                        categorical_shap = categorical_shap.cpu().numpy()
                    category_importance['categorical_features'] = float(np.abs(categorical_shap).sum())
                else:
                    # å³ä½¿æ²¡æœ‰å¯ç”¨ç±»åˆ«ç‰¹å¾ï¼Œä¹Ÿè®¡ç®—SHAPå€¼ï¼ˆå› ä¸ºä¼ é€’äº†é›¶å¼ é‡ï¼‰
                    categorical_shap = shap_values[2]
                    if torch.is_tensor(categorical_shap):
                        categorical_shap = categorical_shap.cpu().numpy()
                    category_importance['categorical_features'] = float(np.abs(categorical_shap).sum())
            
            # 4. åºåˆ—ç‰¹å¾é‡è¦æ€§ (ç¬¬å››ä¸ªè¾“å…¥)
            if len(shap_values) > 3 and shap_values[3] is not None and self.model.sequence_features_enabled:
                sequence_shap = shap_values[3]
                if torch.is_tensor(sequence_shap):
                    sequence_shap = sequence_shap.cpu().numpy()
                category_importance['sequence_features'] = float(np.abs(sequence_shap).sum())
            
            # 5. æ–‡æœ¬ç‰¹å¾é‡è¦æ€§ (ç¬¬äº”ä¸ªè¾“å…¥)
            if len(shap_values) > 4 and shap_values[4] is not None and self.model.text_features_enabled:
                text_shap = shap_values[4]
                if torch.is_tensor(text_shap):
                    text_shap = text_shap.cpu().numpy()
                category_importance['text_features'] = float(np.abs(text_shap).sum())
            
            # å½’ä¸€åŒ–ä¸ºç™¾åˆ†æ¯”
            total_importance = sum(category_importance.values())
            if total_importance > 0:
                for category in category_importance:
                    category_importance[category] = (category_importance[category] / total_importance) * 100
            
            logger.info(f"Level 1 å¤§ç±»åˆ«é‡è¦æ€§è®¡ç®—å®Œæˆ: {category_importance}")
            return category_importance
            
        except Exception as e:
            logger.error(f"Level 1 é‡è¦æ€§è®¡ç®—å¤±è´¥: {e}", exc_info=True)
            return {}
    
    def calculate_level2_importance(self, explainer: Any,
                                background_inputs: List[torch.Tensor],
                                eval_inputs: List[torch.Tensor]) -> Dict[str, float]:
        """
        Level 2: è®¡ç®—å…·ä½“æ•°å€¼ç‰¹å¾çš„è¯¦ç»†é‡è¦æ€§ï¼ˆæŸ±çŠ¶å›¾ç›®æ ‡ï¼‰
        
        Returns:
            Dict[str, float]: å…·ä½“æ•°å€¼ç‰¹å¾çš„SHAPé‡è¦æ€§
        """
        try:
            # è®¡ç®—SHAPå€¼
            shap_values = explainer.shap_values(eval_inputs, check_additivity=False)
            
            # è·å–æ•°å€¼ç‰¹å¾çš„SHAPå€¼ï¼ˆå‡è®¾æ˜¯ç¬¬ä¸€ä¸ªè¾“å…¥ï¼‰
            if len(shap_values) == 0 or shap_values[0] is None:
                logger.warning("æ— æ³•è·å–æ•°å€¼ç‰¹å¾çš„SHAPå€¼")
                return {}
            
            numeric_shap = shap_values[0]
            if torch.is_tensor(numeric_shap):
                numeric_shap = numeric_shap.cpu().numpy()
            
            # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡ç»å¯¹SHAPå€¼
            mean_abs_shap = np.abs(numeric_shap).mean(axis=0)
            
            # ä»é…ç½®æ–‡ä»¶åŠ¨æ€è·å–ç‰¹å¾åç§°
            feature_names = self._extract_numeric_feature_names()
            
            # æ„å»ºé‡è¦æ€§å­—å…¸
            feature_importance = {}
            for i, (name, importance) in enumerate(zip(feature_names, mean_abs_shap)):
                if i < len(feature_names):
                    feature_importance[name] = float(importance)
            
            # æŒ‰é‡è¦æ€§æ’åºï¼Œå–Top 20
            sorted_importance = dict(
                sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:20]
            )
            
            logger.info(f"Level 2 å…·ä½“ç‰¹å¾é‡è¦æ€§è®¡ç®—å®Œæˆï¼ŒTop {len(sorted_importance)} ç‰¹å¾")
            return sorted_importance
            
        except Exception as e:
            logger.error(f"Level 2 é‡è¦æ€§è®¡ç®—å¤±è´¥: {e}", exc_info=True)
            return {}
    
    def _extract_numeric_feature_names(self) -> List[str]:
        """ä»é…ç½®æ–‡ä»¶ä¸­åŠ¨æ€æå–æ•°å€¼ç‰¹å¾åç§°"""
        feature_names = []
        
        if hasattr(self.cfg.data.tabular_features, 'numeric_features'):
            num_cfg = self.cfg.data.tabular_features.numeric_features
            
            # flow_features
            if hasattr(num_cfg, 'flow_features'):
                feature_names.extend(num_cfg.flow_features)
            
            # x509_features  
            if hasattr(num_cfg, 'x509_features'):
                feature_names.extend(num_cfg.x509_features)
                
            # dns_features
            if hasattr(num_cfg, 'dns_features'):
                feature_names.extend(num_cfg.dns_features)
        
        # å¦‚æœç‰¹å¾åç§°æ•°é‡ä¸å®é™…ç»´åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨é€šç”¨åç§°
        expected_count = self.feature_dims['numeric_dims']
        if len(feature_names) != expected_count:
            logger.warning(f"ç‰¹å¾åç§°æ•°é‡({len(feature_names)})ä¸ç»´åº¦({expected_count})ä¸åŒ¹é…")
            feature_names = [f"numeric_feature_{i}" for i in range(expected_count)]
        
        return feature_names
    
    def calculate_comprehensive_analysis(self, background_inputs: List[torch.Tensor],
                                     eval_inputs: List[torch.Tensor]) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„åˆ†å±‚SHAPåˆ†æ"""
        # ======================================================================
        # ğŸ”´ ç»ˆæä¿®å¤: é€€å‡º Inference Mode + å¼€å¯ Grad
        # PyTorch Lightning çš„ test é˜¶æ®µé»˜è®¤å¤„äº inference_mode (æ¯” no_grad æ›´å¼º)
        # å¿…é¡»æ˜¾å¼é€€å‡º inference_mode æ‰èƒ½æ„å»ºè®¡ç®—å›¾
        # ======================================================================
        with torch.inference_mode(False):  # 1. é€€å‡ºæ¨ç†æ¨¡å¼
            with torch.enable_grad():      # 2. å¼€å¯æ¢¯åº¦è®¡ç®—
                
                # 3. å†æ¬¡ç¡®ä¿æ¨¡å‹å‚æ•°å…è®¸æ±‚å¯¼ (åŒé‡ä¿é™©)
                for param in self.wrapper.parameters():
                    param.requires_grad = True
                
                # ç¡®ä¿è¾“å…¥å¼ é‡å…·æœ‰æ¢¯åº¦
                def _ensure_gradients(inputs: List[torch.Tensor]) -> List[torch.Tensor]:
                    return [inp.detach().clone().requires_grad_(True) if isinstance(inp, torch.Tensor) else inp 
                           for inp in inputs]
                
                background_inputs = _ensure_gradients(background_inputs)
                eval_inputs = _ensure_gradients(eval_inputs)
                
                # éªŒè¯è®¡ç®—å›¾è¿é€šæ€§
                test_output = self.wrapper(*background_inputs)
                if test_output.grad_fn is None:
                    logger.error("âŒ [Fatal] Wrapper è¾“å‡ºæ²¡æœ‰ grad_fnï¼è®¡ç®—å›¾ä¾ç„¶æ–­è£‚ã€‚")
                    logger.error(f"å½“å‰æ¢¯åº¦çŠ¶æ€: is_grad_enabled={torch.is_grad_enabled()}, is_inference_mode={torch.is_inference_mode_enabled()}")
                    raise RuntimeError("æ— æ³•æ„å»ºè®¡ç®—å›¾ï¼Œè¯·æ£€æŸ¥ PyTorch ç‰ˆæœ¬æˆ– Lightning é…ç½®ã€‚")
                
                logger.info(f"âœ… è®¡ç®—å›¾æ£€æŸ¥é€šè¿‡! Output grad_fn: {test_output.grad_fn}")
                
                # åˆå§‹åŒ–DeepExplainer
                if shap is None:
                    raise ImportError("SHAP library is not installed. Please install it with: pip install shap")
                explainer = shap.DeepExplainer(self.wrapper, background_inputs)
        
                # Level 1: å¤§ç±»åˆ«åˆ†æï¼ˆé¥¼å›¾ï¼‰
                level1_results = self.calculate_level1_importance(explainer, background_inputs, eval_inputs)
        
                # Level 2: å…·ä½“ç‰¹å¾åˆ†æï¼ˆæŸ±çŠ¶å›¾ï¼‰
                level2_results = self.calculate_level2_importance(explainer, background_inputs, eval_inputs)
        
                # æ„å»ºå®Œæ•´ç»“æœ
                comprehensive_results = {
                    'level1_category_importance': level1_results,
                    'level2_numeric_importance': level2_results,
                    'feature_classification': self.feature_classification,
                    'dimension_info': self.feature_dims,
                    'analysis_metadata': {
                        'total_background_samples': background_inputs[0].shape[0] if background_inputs[0] is not None else 0,
                        'total_eval_samples': eval_inputs[0].shape[0] if eval_inputs[0] is not None else 0,
                        'shap_method': 'DeepLIFT (check_additivity=False)',
                        'model_type': self._detect_model_type(),
                        'feature_hierarchy': self._get_feature_hierarchy()
                    }
                }
        
                return comprehensive_results
    
    def _detect_model_type(self) -> str:
        """æ£€æµ‹å½“å‰æ¨¡å‹ç±»å‹"""
        from .multi_model_adapter import MultiModelSHAPAdapter
        adapter = MultiModelSHAPAdapter()
        return adapter.auto_detect_model_type(self.model)
    
    def _get_feature_hierarchy(self) -> Dict[str, Any]:
        """è·å–ç‰¹å¾å±‚æ¬¡ä¿¡æ¯"""
        hierarchy = {}
        for category, features in self.feature_classification.items():
            hierarchy[category] = {
                'count': len(features),
                'features': features[:5] if len(features) > 5 else features,  # åªæ˜¾ç¤ºå‰5ä¸ª
                'target_analysis': 'both' if category == 'numeric_features' else 'pie_chart'
            }
        return hierarchy
    
    def validate_computation_readiness(self, background_inputs: List[torch.Tensor],
                                   eval_inputs: List[torch.Tensor]) -> Dict[str, Any]:
        """éªŒè¯è®¡ç®—å‡†å¤‡æƒ…å†µ"""
        validation_result = {
            'is_ready': True,
            'issues': [],
            'warnings': []
        }
        
        # æ£€æŸ¥è¾“å…¥æ•°é‡
        expected_inputs = 5  # numeric, domain, categorical, sequence, text
        if len(background_inputs) != expected_inputs:
            validation_result['issues'].append(
                f"èƒŒæ™¯è¾“å…¥æ•°é‡é”™è¯¯: æœŸæœ›{expected_inputs}, å®é™…{len(background_inputs)}"
            )
            validation_result['is_ready'] = False
        
        if len(eval_inputs) != expected_inputs:
            validation_result['issues'].append(
                f"è¯„ä¼°è¾“å…¥æ•°é‡é”™è¯¯: æœŸæœ›{expected_inputs}, å®é™…{len(eval_inputs)}"
            )
            validation_result['is_ready'] = False
        
        # æ£€æŸ¥ç»´åº¦åŒ¹é…
        for i, (bg_input, eval_input) in enumerate(zip(background_inputs, eval_inputs)):
            if bg_input is None or eval_input is None:
                continue
                
            if bg_input.shape[-1] != eval_input.shape[-1]:
                validation_result['issues'].append(
                    f"è¾“å…¥{i}ç»´åº¦ä¸åŒ¹é…: èƒŒæ™¯{bg_input.shape[-1]}, è¯„ä¼°{eval_input.shape[-1]}"
                )
                validation_result['is_ready'] = False
        
        # æ£€æŸ¥ç‰¹å¾åˆ†ç±»ä¸€è‡´æ€§
        enabled_features = []
        if self.model.text_features_enabled:
            enabled_features.append('text')
        if self.model.sequence_features_enabled:
            enabled_features.append('sequence')
        if self.model.domain_embedding_enabled:
            enabled_features.append('domain')
        enabled_features.append('numeric')  # å§‹ç»ˆå¯ç”¨
        
        if len(enabled_features) < 2:
            validation_result['warnings'].append(
                f"å¯ç”¨çš„ç‰¹å¾è§†å›¾è¾ƒå°‘: {enabled_features}ï¼Œåˆ†æç»“æœå¯èƒ½ä¸å¤Ÿå…¨é¢"
            )
        
        return validation_result