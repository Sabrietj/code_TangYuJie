#!/usr/bin/env python3
"""
å¤šè§†å›¾æµé‡åˆ†ç±»æ¨¡å‹ SHAP åˆ†æç¤ºä¾‹
æ”¯æŒ flow_bert_multiview, ssl, ssl_mlm, ssl_seq2stat æ¨¡å‹

ä½¿ç”¨æ–¹æ³•:
python multiview_shap_example.py --model_type ssl --batch_data_path batch_data.pkl
"""

import argparse
import pickle
import logging
from pathlib import Path
from typing import Dict, Any

# å¯¼å…¥SHAPåˆ†ææ¡†æ¶
from universal_analyzer import UniversalSHAPAnalyzer

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_config(model_type: str) -> Dict[str, Any]:
    """åŠ è½½æ¨¡å‹ç‰¹å®šé…ç½®"""
    config_path = Path(__file__).parent / "multiview_config.yaml"
    
    # è¿™é‡Œåº”è¯¥è§£æYAMLæ–‡ä»¶ï¼Œç®€åŒ–èµ·è§è¿”å›åŸºç¡€é…ç½®
    base_config = {
        'shap': {
            'enabled': True,
            'num_background_samples': 50,
            'max_evals': 500,
            'save_plots': True,
            'save_detailed_results': True,
            'enable_data_validation': True,
            'enable_score_rebalancing': True,
            'enabled_strategies': ['numeric', 'sequence', 'text', 'categorical']
        },
        'output': {
            'base_dir': './shap_results',
            'create_timestamp_dirs': True
        }
    }
    
    # æ ¹æ®æ¨¡å‹ç±»å‹æ·»åŠ ç‰¹å®šé…ç½®
    model_configs = {
        'flow_bert_multiview': {
            'decompose_combined_text': True,
            'exclude_features': ['idx', 'uid', 'sequence_mask', 'combined_text']
        },
        'ssl': {
            'decompose_combined_text': True,
            'exclude_features': ['idx', 'uid', 'sequence_mask', 'ssl_mask', 'combined_text']
        },
        'ssl_mlm': {
            'decompose_combined_text': True,
            'exclude_features': ['idx', 'uid', 'sequence_mask', 'mlm_mask', 'sequence_mlm_mask', 'combined_text']
        },
        'ssl_seq2stat': {
            'decompose_combined_text': True,
            'exclude_features': ['idx', 'uid', 'sequence_mask', 'seq2stat_mask', 'combined_text']
        }
    }
    
    if model_type in model_configs:
        base_config.update(model_configs[model_type])
    
    return base_config

def load_batch_data(data_path: str) -> Dict[str, Any]:
    """åŠ è½½æ‰¹æ¬¡æ•°æ®"""
    try:
        with open(data_path, 'rb') as f:
            batch_data = pickle.load(f)
        logger.info(f"æˆåŠŸåŠ è½½æ‰¹æ¬¡æ•°æ®ï¼ŒåŒ…å« {len(batch_data)} ä¸ªå­—æ®µ")
        return batch_data
    except Exception as e:
        logger.error(f"åŠ è½½æ‰¹æ¬¡æ•°æ®å¤±è´¥: {e}")
        raise

def create_mock_model(model_type: str):
    """åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹ç”¨äºæ¼”ç¤º"""
    # è¿™é‡Œåº”è¯¥åŠ è½½å®é™…è®­ç»ƒå¥½çš„æ¨¡å‹
    # ä¸ºäº†æ¼”ç¤ºï¼Œåˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿå¯¹è±¡
    class MockModel:
        def __init__(self, model_type):
            self.model_type = model_type
            self.device = 'cpu'
        
        def __call__(self, batch: Dict[str, Any]) -> Dict[str, Any]:
            # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­
            batch_size = batch.get('numeric_features', batch.get('uid', [0])).__class__.__len__([0])
            return {
                'classification_logits': [[0.3, 0.7] for _ in range(batch_size)],
                'multiview_embeddings': [[0.1, 0.2, 0.3] for _ in range(batch_size)]
            }
        
        def eval(self):
            pass
    
    return MockModel(model_type)

def run_shap_analysis(model_type: str, batch_data_path: str):
    """è¿è¡ŒSHAPåˆ†æ"""
    logger.info(f"å¼€å§‹ä¸ºæ¨¡å‹ {model_type} è¿è¡ŒSHAPåˆ†æ...")
    
    # 1. åŠ è½½é…ç½®
    config = load_config(model_type)
    logger.info("é…ç½®åŠ è½½å®Œæˆ")
    
    # 2. åŠ è½½æ‰¹æ¬¡æ•°æ®
    batch_data = load_batch_data(batch_data_path)
    
    # 3. åŠ è½½æ¨¡å‹
    model = create_mock_model(model_type)
    logger.info(f"æ¨¡å‹ {model_type} åŠ è½½å®Œæˆ")
    
    # 4. åˆ›å»ºSHAPåˆ†æå™¨
    analyzer = UniversalSHAPAnalyzer(config)
    logger.info("SHAPåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    # 5. è¿è¡Œåˆ†æ
    try:
        results = analyzer.analyze(model, batch_data, model_type)
        logger.info("SHAPåˆ†æå®Œæˆ")
        
        # 6. ä¿å­˜ç»“æœ
        output_path = analyzer.save_results(results, f"{model_type}_shap_analysis")
        logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        # 7. æ‰“å°æ‘˜è¦
        if 'analysis_summary' in results:
            summary = results['analysis_summary']
            print(f"\n=== {model_type} SHAPåˆ†ææ‘˜è¦ ===")
            print(f"æ€»ç‰¹å¾æ•°: {summary.get('total_features_analyzed', 0)}")
            print(f"æˆåŠŸåˆ†æ: {summary.get('successful_analyses', 0)}")
            print(f"å¤±è´¥åˆ†æ: {summary.get('failed_analyses', 0)}")
            print(f"å‘ç°ç‰¹å¾ç±»å‹: {', '.join(summary.get('feature_types_found', []))}")
        
        # 8. æ‰“å°é‡è¦ç‰¹å¾ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if 'aggregated_importance' in results and 'sorted_importance' in results['aggregated_importance']:
            sorted_importance = results['aggregated_importance']['sorted_importance']
            print(f"\n=== å‰10ä¸ªé‡è¦ç‰¹å¾ ===")
            for i, (feature_name, importance_data) in enumerate(list(sorted_importance.items())[:10]):
                score = importance_data.get('score', 0)
                feature_type = importance_data.get('type', 'unknown')
                print(f"{i+1:2d}. {feature_name:30s} [åˆ†æ•°: {score:.4f}, ç±»å‹: {feature_type}]")
        
        return results
        
    except Exception as e:
        logger.error(f"SHAPåˆ†æå¤±è´¥: {e}")
        raise

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¤šè§†å›¾æµé‡åˆ†ç±»æ¨¡å‹ SHAP åˆ†æ')
    parser.add_argument(
        '--model_type',
        type=str,
        required=True,
        choices=['flow_bert_multiview', 'ssl', 'ssl_mlm', 'ssl_seq2stat'],
        help='æ¨¡å‹ç±»å‹'
    )
    parser.add_argument(
        '--batch_data_path',
        type=str,
        required=True,
        help='æ‰¹æ¬¡æ•°æ®æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--config_path',
        type=str,
        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        default='./shap_results',
        help='è¾“å‡ºç›®å½•'
    )
    
    args = parser.parse_args()
    
    # è¿è¡ŒSHAPåˆ†æ
    results = run_shap_analysis(args.model_type, args.batch_data_path)
    
    print("\nâœ… SHAPåˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")

if __name__ == "__main__":
    main()