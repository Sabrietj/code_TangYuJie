import os
import pandas as pd
import numpy as np
import ast
from tqdm import tqdm

# ================= é…ç½® =================
# æŒ‡å‘ embed_feature è¾“å‡ºçš„åˆå¹¶æ–‡ä»¶ç›®å½•
DATASET_DIR = "/root/autodl-fs/processed_data/CIC-IDS-2017-session-srcIP_srcPort_dstIP_dstPort_proto"


# =======================================

def verify_merged_sorted():
    print(f"ğŸ” [Step 2] å¼€å§‹æ ¡éªŒåˆå¹¶åçš„å…¨å±€æ—¶åº: {DATASET_DIR}")

    flow_path = os.path.join(DATASET_DIR, "all_flow.csv")
    session_path = os.path.join(DATASET_DIR, "all_session.csv")

    if not os.path.exists(flow_path) or not os.path.exists(session_path):
        print("âŒ é”™è¯¯: all_flow.csv æˆ– all_session.csv ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆå¹¶ä»£ç ï¼")
        return

    # --- 1. æ ¡éªŒ Flow é¡ºåº ---
    print("   æ­£åœ¨è¯»å– all_flow.csv (åªè¯»æ—¶é—´åˆ—)...")
    # å°è¯•è¯»å– conn.ts æˆ– ts
    df_flow_header = pd.read_csv(flow_path, nrows=0)
    ts_col = 'conn.ts' if 'conn.ts' in df_flow_header.columns else 'ts'

    # é€å—è¯»å–ä»¥èŠ‚çœå†…å­˜ï¼Œæ£€æŸ¥å•è°ƒæ€§
    prev_ts = -1.0
    flow_is_sorted = True
    row_count = 0

    chunksize = 500000
    for chunk in tqdm(pd.read_csv(flow_path, usecols=[ts_col], chunksize=chunksize), desc="æ ¡éªŒ Flow æ—¶åº"):
        ts_values = chunk[ts_col].values

        # æ£€æŸ¥å½“å‰å—å†…éƒ¨æ˜¯å¦æ’åº
        if not (np.diff(ts_values) >= 0).all():
            flow_is_sorted = False
            break

        # æ£€æŸ¥ä¸ä¸Šä¸€å—çš„è¿æ¥å¤„
        if row_count > 0:
            if ts_values[0] < prev_ts:
                flow_is_sorted = False
                break

        prev_ts = ts_values[-1]
        row_count += len(chunk)

    if flow_is_sorted:
        print(f"âœ… Flow æ•°æ®ä¸¥æ ¼æŒ‰æ—¶é—´å‡åºæ’åˆ— (å…± {row_count} è¡Œ)")
    else:
        print(f"âŒ Flow æ•°æ®å­˜åœ¨ä¹±åºï¼è¯·æ£€æŸ¥ merge_csv_files ä¸­çš„æ’åºé€»è¾‘ã€‚")
        return  # Flow ä¹±åºåˆ™æ— éœ€ç»§ç»­æ£€æŸ¥ Session

    # --- 2. æ ¡éªŒ Session é¡ºåº ---
    print("\n   æ­£åœ¨æ ¡éªŒ Session æ—¶åº (è¿™éœ€è¦åŠ è½½ UID æ˜ å°„ï¼Œç¨æ…¢)...")

    # åŠ è½½ Flow UID -> TS æ˜ å°„
    print("   åŠ è½½ Flow ç´¢å¼•...")
    df_flow = pd.read_csv(flow_path, usecols=['uid', ts_col])
    uid_to_time = dict(zip(df_flow['uid'], df_flow[ts_col]))

    print("   è¯»å– Session å¹¶è®¡ç®—çœŸå®æ—¶é—´...")
    df_session = pd.read_csv(session_path)

    def get_start_time(uid_list_str):
        try:
            if isinstance(uid_list_str, str):
                uids = ast.literal_eval(uid_list_str)
            else:
                uids = uid_list_str
            if not uids: return -1
            # è¿™é‡Œçš„é€»è¾‘å¿…é¡»å’Œ merge ä»£ç ä¸€è‡´ï¼šå– min
            return min([uid_to_time.get(uid, float('inf')) for uid in uids])
        except:
            return -1

    # è®¡ç®—æ—¶é—´
    tqdm.pandas(desc="è®¡ç®— Session æ—¶é—´")
    df_session['calc_ts'] = df_session['flow_uid_list'].progress_apply(get_start_time)

    # æ£€æŸ¥å•è°ƒæ€§
    # è¿‡æ»¤æ‰æ— æ³•è®¡ç®—æ—¶é—´çš„è¡Œï¼ˆé€šå¸¸æ˜¯ -1 æˆ– infï¼‰
    valid_ts = df_session[df_session['calc_ts'] > 0]['calc_ts'].values

    if (np.diff(valid_ts) >= 0).all():
        print(f"âœ… [Step 2] Session æ•°æ®ä¸¥æ ¼æŒ‰æ—¶é—´å‡åºæ’åˆ—ï¼")
        print(f"   Validation Passed. ä½ çš„æ•°æ®å·²ç»å‡†å¤‡å¥½è¿›è¡Œæ¦‚å¿µæ¼‚ç§»å®éªŒäº†ã€‚")
    else:
        # æ‰¾å‡ºé”™è¯¯ä½ç½®
        diffs = np.diff(valid_ts)
        error_indices = np.where(diffs < 0)[0]
        print(f"âŒ [Step 2] Session æ•°æ®å­˜åœ¨ä¹±åºï¼")
        print(f"   å‘ç° {len(error_indices)} å¤„æ—¶é—´å€’æµã€‚")
        print(
            f"   ç¤ºä¾‹é”™è¯¯: ç´¢å¼• {error_indices[0]} çš„æ—¶é—´ {valid_ts[error_indices[0]]} > ç´¢å¼• {error_indices[0] + 1} çš„æ—¶é—´ {valid_ts[error_indices[0] + 1]}")


if __name__ == "__main__":
    verify_merged_sorted()